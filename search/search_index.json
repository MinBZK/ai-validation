{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"AI Validation Team","text":""},{"location":"about/contact/","title":"Contact","text":""},{"location":"about/contact/#contact","title":"Contact","text":"<p>Contact us at ai-validatie@minbzk.nl.</p>"},{"location":"about/team/","title":"Former team members","text":""},{"location":"about/team/#former-team-members","title":"Former team members","text":"<p>The AI Validation team operated from August 2023 through March 2025.</p>"},{"location":"about/team/#robbert-bos","title":"Robbert Bos","text":"<p>Product Owner</p> <p></p> <p>Robbert has been on a mission for over 15 years to enhance the transparency and collaboration within AI projects. Before joining this team, he founded several data science and tech companies (partly) dedicated to this cause. Robbert is passionate about solving complex problems where he connects business needs with technology and involves others in how these solutions can improve their work.</p> <p> robbertbos</p> <p> Robbert Bos</p>"},{"location":"about/team/#ravi-meijer","title":"Ravi Meijer","text":"<p>Product Researcher</p> <p></p> <p>Ravi is an accomplished data scientist with expertise in machine learning, responsible AI, and the data science lifecycle. Her background in AI fuels her passion for solving complex problems and driving innovation for positive social impact.</p> <p> ravimeijerrig</p> <p> Ravi Meijer</p>"},{"location":"about/team/#christopher-spelt","title":"Christopher Spelt","text":"<p>Engineer</p> <p></p> <p>After graduating in pure mathematics, Christopher transitioned into machine learning. He is passionate about solving complex problems, especially those that have a societal impact. My expertise lies in math, machine learning theory and I'm skilled in Python.</p> <p> ChristopherSpelt</p> <p> Christopher Spelt</p>"},{"location":"about/team/#robbert-uittenbroek","title":"Robbert Uittenbroek","text":"<p>Engineer</p> <p></p> <p>Robbert is a highly enthusiastic full-stack engineer with a Bachelor's degree in Computer Science from the Hanze University of Applied Sciences in Groningen. He is passionate about building secure, compliant, and ethical solutions, and thrives in collaborative environments. Robbert is eager to leverage his skills and knowledge to help shape and propel the future of IT within the government.</p> <p> uittenbroekrobbert</p> <p> Robbert Uittenbroek</p>"},{"location":"about/team/#ruben-rouwhof","title":"Ruben Rouwhof","text":"<p>UX/UI Designer</p> <p></p> <p>Ruben is a dedicated UX/UI Designer focused on crafting user-centric digital experiences. He is involved in projects from start to finish, covering user research, design, and technical implementation.</p> <p> rubenrouwhof</p> <p> Ruben Rouwhof</p> <p> rubenrouwhof.nl</p>"},{"location":"about/team/#renate-burema","title":"Renate Burema","text":"<p>Intern</p> <p></p> <p>Renate is a master student Artificial Intelligence at Utrecht University. She is an intern writing her master thesis. Furthermore, she is passionate for the topics natural language processing and fairness.</p> <p> Renate Burema</p>"},{"location":"about/team/#anne-schuth","title":"Anne Schuth","text":"<p>Engineering Manager</p> <p></p> <p>Anne used to be a Machine Learning Engineering Manager at Spotify and previously held roles at DPG Media, Blendle, and Google AI. He holds a PhD from the University of Amsterdam.</p> <p> anneschuth</p> <p> Anne Schuth</p> <p> anneschuth.nl</p>"},{"location":"about/team/#laurens-weijs","title":"Laurens Weijs","text":"<p>Engineer</p> <p></p> <p>Laurens is a passionate guy with a love for innovation and doing things differently. With a background in Econometrics and Computer Science he loves to tackle the IT challenges of the Government by helping other people through extensive knowledge sharing on stage, building neural networks himself, or building a strong community.</p> <p> laurensWe</p> <p> Laurens Weijs</p>"},{"location":"about/team/#berry-den-hartog","title":"Berry den Hartog","text":"<p>Engineer</p> <p></p> <p>Berry is a software engineer passionate about problem-solving and system optimization, with expertise in Go, Python, and C++. Specialized in architecting high-volume data processing systems and implementing Lean-Agile and DevOps practices. Experienced in managing end-to-end processes from hardware provisioning to software deployment and release.</p> <p> berrydenhartog</p> <p> Berry den Hartog</p>"},{"location":"about/team/#guusje-juijn","title":"Guusje Juijn","text":"<p>Trainee</p> <p></p> <p>Guusje has a background in Artificial Intelligence, is experienced in Python and machine learning and has a strong interest in AI ethics. During her traineeship at the Dutch Government, she gained valuable experience in both a policy department and a software engineering team.</p> <p> GuusjeJuijn</p> <p> Guusje Juijn</p>"},{"location":"adrs/0001-adrs/","title":"ADR-0001 ADRs","text":""},{"location":"adrs/0001-adrs/#adr-0001-adrs","title":"ADR-0001 ADRs","text":""},{"location":"adrs/0001-adrs/#context","title":"Context","text":"<p>In modern software development practices, the use of Architecture Decision Records (ADRs) has become increasingly common. ADRs are documents that capture important architectural decisions made during the development process. These decisions play a crucial role in guiding the development team and ensuring consistency and coherence in the architecture of the software system.</p>"},{"location":"adrs/0001-adrs/#assumptions","title":"Assumptions","text":"<ol> <li>ADRs provide a structured way to document and communicate architectural decisions.</li> <li>Publishing ADRs publicly fosters transparency and facilitates collaboration among team members and stakeholders.</li> <li>ADRs help in onboarding new team members by providing insights into past decisions and their rationale.</li> </ol>"},{"location":"adrs/0001-adrs/#decision","title":"Decision","text":"<p>We will utilize ADRs in our team to document and communicate architectural decisions effectively. Furthermore, we will publish these ADRs publicly to promote transparency and facilitate collaboration.</p>"},{"location":"adrs/0001-adrs/#template","title":"Template","text":"<p>Use the template below to add an ADR:</p> <pre><code># ADR-XXXX Title\n\n## Context\n\nWhat is the issue that we're seeing that is motivating this decision or change?\n\n## Assumptions\n\nAnything that could cause problems if untrue now or later. (optional)\n\n## Decision\n\nWhat is the change that we're proposing and/or doing?\n\n## Risks\n\nAnything that could cause malfunction, delay, or other negative impacts. (optional)\n\n## Consequences\n\nWhat becomes easier or more difficult to do because of this change?\n\n## More Information\n\nProvide additional evidence/confidence for the decision outcome\nLinks to other decisions and resources might here appear as well. (optional)\n</code></pre>"},{"location":"adrs/0002-code-platform/","title":"ADR-0002 Code Platform","text":""},{"location":"adrs/0002-code-platform/#adr-0002-code-platform","title":"ADR-0002 Code Platform","text":""},{"location":"adrs/0002-code-platform/#context","title":"Context","text":"<p>In the landscape of software development, the choice of coding platform significantly impacts developer productivity, collaboration, and code quality. it's crucial to evaluate and select a coding platform that aligns with our development needs and fosters efficient workflows.</p>"},{"location":"adrs/0002-code-platform/#assumptions","title":"Assumptions","text":"<p>The following assumptions are made:</p> <ul> <li>Our work should be visible to external teams to promote transparency and facilitate collaboration.</li> <li>The coding platform should be easily available for developers.</li> <li>The coding platform should offers collaboration tools between developers and the community.</li> <li>The coding platform should offers security and dependency management tools.</li> <li>The pricing model should be suitable for our budget and needs. Currently meaning no budgets.</li> </ul>"},{"location":"adrs/0002-code-platform/#decision","title":"Decision","text":"<p>After careful consideration and evaluation of various options like GitHub, GitLab and BitBucket, we propose adopting GitHub as our primary coding platform. The decision is based on the following factors:</p> <p>Costs: There are currently no costs associate in using GitHub for our use cases.</p> <p>Features and Functionality: GitHub offers a comprehensive set of features essential for modern software development and collaboration with external teams, including version control, code review, issue tracking, continuous integration, and deployment automation.</p> <p>Security: GitHub offers a complete set of security features essential to secure development like dependency management and security scanning.</p> <p>Community and Ecosystem: GitHub boasts a vibrant community and ecosystem, facilitating knowledge sharing, collaboration, and access to third-party tools, and services that can enhance our development workflows. Within our organization we have easy access to the team managing the GitHub organization.</p> <p>Usability and User Experience: A user-friendly interface and intuitive workflows are essential for maximizing developer productivity and minimizing onboarding time. GitHub offers a streamlined user experience and customizable workflows that align with our team's preferences and practices.</p>"},{"location":"adrs/0002-code-platform/#risks","title":"Risks","text":"<p>Currently the organization of MinBZK on GitHub does not have a lot of <code>people</code> indicating that our team is an early adapter of the platform within the organization. This might impact our features due to cost constrains.</p>"},{"location":"adrs/0002-code-platform/#consequences","title":"Consequences","text":"<p>If we choose another tool in the future we need to migrate our codebase, and potentially need to rewrite some specific GitHub features that cannot be used in another tool.</p>"},{"location":"adrs/0002-code-platform/#more-information","title":"More Information","text":"<p>Alternatives considered:</p> <ul> <li>BitBucket</li> <li>GitLab</li> <li>Forgejo</li> </ul>"},{"location":"adrs/0003-ci-cd/","title":"ADR-0003 CI/CD Tooling","text":""},{"location":"adrs/0003-ci-cd/#adr-0003-cicd-tooling","title":"ADR-0003 CI/CD Tooling","text":""},{"location":"adrs/0003-ci-cd/#context","title":"Context","text":"<p>Our development team wants to implement a CI/CD solution to streamline the build, testing, and deployment workflows of our software products. Currently, our codebase resides on GitHub, and we leverage Kubernetes as our chosen orchestration platform, managed by the DigiLab platform team.</p>"},{"location":"adrs/0003-ci-cd/#decision","title":"Decision","text":"<p>We will use the following tools for CI/CD pipeline:</p> <ul> <li>Continuous Integration (CI): GitHub Actions will be employed to facilitate the automated testing of our applications.</li> <li>Continuous Deployment (CD): We will utilize Flux for managing the deployment process of our applications. Flux reads from github to deploy.</li> </ul>"},{"location":"adrs/0003-ci-cd/#consequences","title":"Consequences","text":"<p>GitHub Actions aligns with our existing infrastructure, ensuring seamless integration with our codebase and minimizing operational overhead. GitHub Actions' specific syntax for CI results in vendor lock-in, necessitating significant effort to migrate to an alternative CI system in the future.</p> <p>Flux, being a GitOps operator for Kubernetes, offers a declarative approach to managing deployments, enhancing reliability and repeatability within our Kubernetes ecosystem.</p>"},{"location":"adrs/0004-software-hosting-platform/","title":"ADR-0004 Software hosting platform","text":""},{"location":"adrs/0004-software-hosting-platform/#adr-0004-software-hosting-platform","title":"ADR-0004 Software hosting platform","text":""},{"location":"adrs/0004-software-hosting-platform/#context","title":"Context","text":"<p>Our team recognizes the necessity of a platform to run our software, as our local machines lack the capacity to handle certain workloads effectively. We have evaluated several options available to us:</p> <ol> <li>Digilab Kubernetes</li> <li>Logius Kubernetes</li> <li>SSC-ICT VMs</li> <li>ODC Noord</li> </ol>"},{"location":"adrs/0004-software-hosting-platform/#assumptions","title":"Assumptions","text":"<p>We operate under the following assumptions:</p> <ul> <li>High availability is not a critical requirement for our software.</li> <li>Our team prioritizes low maintenance solutions.</li> </ul>"},{"location":"adrs/0004-software-hosting-platform/#decision","title":"Decision","text":"<p>We will use Digilab Kubernetes for our workloads.</p>"},{"location":"adrs/0004-software-hosting-platform/#consequences","title":"Consequences","text":"<p>By choosing Digilab Kubernetes, we gain access to a namespace within their managed Kubernetes cluster. However, it's important to note that Digilab does not provide any guarantees regarding the availability of the cluster. Should our software require higher availability assurances, we may need to explore alternative solutions.</p>"},{"location":"adrs/0005-python-tooling/","title":"ADR-0005 Python coding standard and tools","text":""},{"location":"adrs/0005-python-tooling/#adr-0005-python-coding-standard-and-tools","title":"ADR-0005 Python coding standard and tools","text":""},{"location":"adrs/0005-python-tooling/#context","title":"Context","text":"<p>In modern software development, maintaining code quality is crucial for readability, maintainability, and collaboration. Python, being a dynamically typed language, requires robust tooling to ensure code consistency and type safety. Manual enforcement of coding standards is time-consuming and error-prone. Hence, adopting automated tooling to streamline this process is imperative.</p>"},{"location":"adrs/0005-python-tooling/#decision","title":"Decision","text":"<p>We will use these standards and tools for our own projects:</p> <ul> <li>Google style guide</li> <li>Ruff<ul> <li>Rules: [I, SIM, B, UP, F, E]</li> <li>Formatter</li> </ul> </li> <li>Pyright: A static type checker for Python, ensuring type safety and reducing potential runtime errors.</li> <li>pre-commit: A framework for managing and maintaining multi-language pre-commit hooks.</li> </ul> <p>Working with external projects these coding standards will not always be possible. but we will try to integrate them as much as possible.</p>"},{"location":"adrs/0005-python-tooling/#consequences","title":"Consequences","text":"<p>Improved Code Quality: Adoption of these tools will lead to improved code quality, consistency, and maintainability across the project.</p> <p>Enhanced Developer Productivity: Automated code formatting and static type checking will reduce manual effort and free developers to focus more on coding logic rather than formatting and type-related issues.</p> <p>Reduced Bug Incidence: Static typing and linting will catch potential bugs and issues early in the development process, reducing the likelihood of runtime errors and debugging efforts.</p> <p>Standardized Development Workflow: By integrating pre-commit hooks, the development workflow will be standardized, ensuring that all developers follow the same code quality standards.</p>"},{"location":"adrs/0006-agile-tooling/","title":"ADR-0006 Agile tooling","text":""},{"location":"adrs/0006-agile-tooling/#adr-0006-agile-tooling","title":"ADR-0006 Agile tooling","text":""},{"location":"adrs/0006-agile-tooling/#context","title":"Context","text":"<p>Our development team wants to enhance transparency and productivity in our software development processes. We are using GitHub for version control and collaboration. However, to further streamline our process, there is a need to incorporate tooling for managing the effort of our team.</p>"},{"location":"adrs/0006-agile-tooling/#decision","title":"Decision","text":"<p>We will use GitHub Projects as our agile process tool</p>"},{"location":"adrs/0006-agile-tooling/#consequences","title":"Consequences","text":"<p>GitHub Projects seamlessly integrates with our existing GitHub repositories, allowing us to manage our Agile processes. within the same ecosystem where our code resides. This integration eliminates the need for additional third-party tools, simplifying our workflow.</p>"},{"location":"adrs/0007-commit-convention/","title":"ADR-0007 Commit convention","text":""},{"location":"adrs/0007-commit-convention/#adr-0007-commit-convention","title":"ADR-0007 Commit convention","text":""},{"location":"adrs/0007-commit-convention/#context","title":"Context","text":"<p>In software development, maintaining clear and consistent commit message conventions is crucial for effective collaboration, code review, and project management. Commit messages serve as a form of documentation, helping developers understand the changes introduced by each commit without having to analyze the code diff extensively.</p>"},{"location":"adrs/0007-commit-convention/#decision","title":"Decision","text":"<p>A commit message must follow the following rules:</p> <ol> <li>The subject line (first line) MUST not be no longer than 50 characters</li> <li>The subject line MUST be in the imperative mood</li> <li>A sentences MUST have Capitalized first word</li> <li>The subject line MUST not end with a punctuation</li> <li>The body line length SHOULD be restricted to 72 characters</li> <li>The body MUST be separate by a blank line from the subject line if used</li> <li>The body SHOULD be used to explain what and why, not how.</li> <li>The body COULD end with a ticket number</li> <li>The Subject line COULD include a ticket number in the following format</li> </ol> <p>\\&lt;ref&gt;-\\&lt;ticketnumber&gt;: subject line</p> <p>An example of a commit message:</p> <p>Fix foo to enable bar</p> <p>or</p> <p>AB-1234: Fix foo to enable bar</p> <p>or</p> <p>Fix foo to enable bar</p> <p>This fixes the broken behavior of component abc caused by problem xyz.</p> <p>If we contribute to projects not started by us we try to follow the above standard unless a specific convention is obvious or required by the project.</p>"},{"location":"adrs/0007-commit-convention/#consequences","title":"Consequences","text":"<p>In some repositories Conventional Commits are used. This ADR does not follow conventional commits.</p>"},{"location":"adrs/0008-architectural-diagram-tooling/","title":"ADR-0008 Architectural Diagram Tooling","text":""},{"location":"adrs/0008-architectural-diagram-tooling/#adr-0008-architectural-diagram-tooling","title":"ADR-0008 Architectural Diagram Tooling","text":""},{"location":"adrs/0008-architectural-diagram-tooling/#context","title":"Context","text":"<p>To communicate our designs in a graphical manner, it is of importance to draw architectural diagrams. For this we use tooling, that supports us in our work. We need to have something that is written so that it can be processed by both people and machine, and we want to have version control on our diagrams.</p>"},{"location":"adrs/0008-architectural-diagram-tooling/#decision","title":"Decision","text":"<p>We will write our architectural diagrams in Markdown-like (.mmmd) in the Mermaid Syntax to edit these diagrams one can use the various plugins. For each project where it is needed, we will add the diagrams in the repository of the subject. The level of detail we will provide in the diagrams is according to the C4-model metamodel on architecture diagramming.</p>"},{"location":"adrs/0008-architectural-diagram-tooling/#consequences","title":"Consequences","text":"<p>Standardized Workflow: By maintaining architecture as code, it will be standardized in our workflow.</p> <p>Version control on diagrams: By using version control, we will be able to collaborate easier on the diagrams, and we will be able to see the history of them.</p> <p>Diagrams are in .md format: By storing our diagrams next to our code, it will be where you need it the most.</p>"},{"location":"adrs/0010-container-registry/","title":"ADR-0010 Container Registry","text":""},{"location":"adrs/0010-container-registry/#adr-0010-container-registry","title":"ADR-0010 Container Registry","text":""},{"location":"adrs/0010-container-registry/#context","title":"Context","text":"<p>Containers allow us to package and run applications in a standardized and portable way. To be able to (re)use and share images, they need to be stored in a registry that is accessible by others.</p> <p>There are many container registries. During research the following registries have been noted:</p> <p>Docker Hub, GitHub Container Registry, Amazon Elastic Container Registry (ECR), Azure Container Registry (ACR), Google Artifact Registry (GAR), Red Hat Quay, GitLab Container Registry, Harbor, Sonatype Nexus Repository Manager, JFrog Artifactory.</p>"},{"location":"adrs/0010-container-registry/#assumptions","title":"Assumptions","text":"<ul> <li>We do not want to host our own registry.</li> <li>The images we create can be kept private or publicly shared.</li> <li>For development and testing, images should be kept private to prevent accidental use of unfinished products.</li> <li>Images we provide are safe and secure. This means a container registry should have the option to (continuously) verify the security status of an image.</li> <li>By configuration, tags can be made immutable, to prevent image tags from being overwritten.</li> <li>The registry keeps logs of events regarding containers.</li> <li>The registry needs to have a Role Based Access model.</li> <li>No additional sign up is required to pull the image</li> <li>We can use a kubernetes authorization token to pull images.</li> <li>The registry has support for scheduled deletion of images by criteria.</li> </ul>"},{"location":"adrs/0010-container-registry/#decision","title":"Decision","text":"<p>We will use GitHub Container Registry.</p> <p>This aligns best with the previously made choices for GitHub as a code repository and CI/CD workflow.</p>"},{"location":"adrs/0010-container-registry/#risks","title":"Risks","text":"<p>Traditionally, Docker Hub has been the place to publish images. Therefore, our images may be more difficult to discover.</p> <p>The following assumptions are not (directly) covered by the chosen registry:</p> <ul> <li>Security scans are not implemented by default, meaning we should find another solution to cover this, for example by using a GitHub Action.</li> <li>Private packages are limited by space and an additional license may be required, see Billing for GitHub Packages.</li> <li>It is unclear if it is possible to overwrite tags.</li> <li>Removing images by criteria is not implemented by default, but could be solved using a GitHub Action.</li> </ul>"},{"location":"adrs/0010-container-registry/#consequences","title":"Consequences","text":"<p>By using GitHub Container Registry we have a container registry we can use both internally as well as share with others. This has low impact, we can always move to another registry since the Open Container Initiative is standardized.</p>"},{"location":"adrs/0010-container-registry/#more-information","title":"More Information","text":"<p>The following sites have been consulted:</p> <ul> <li>Bluelight 'How to choose a container registry'</li> <li>G2 container-registry</li> <li>slashdot container registries</li> <li>Sourceforge Container Registries</li> <li>G2 Alternative Registries</li> <li>Security controls for container registries</li> </ul>"},{"location":"adrs/0011-researcher-in-residence/","title":"ADR-0011 Researcher in Residence","text":""},{"location":"adrs/0011-researcher-in-residence/#adr-0011-researcher-in-residence","title":"ADR-0011 Researcher in Residence","text":""},{"location":"adrs/0011-researcher-in-residence/#context","title":"Context","text":"<p>The AI validation team works transparently. Working with public funds warrants transparency toward the public. Additionally, being transparent aligns with the team's mission of increasing the transparency of public organizations. In line with this reasoning, it is important to be open to researchers interested in the work of the AI validation team. Allowing researchers to conduct research within the team contributes to transparency and enables external perspectives and feedback to be incorporated into the team's work.</p>"},{"location":"adrs/0011-researcher-in-residence/#assumptions","title":"Assumptions","text":"<ul> <li>Having researchers in residence is a mechanism that facilitates transparency.</li> <li>Research enables external feedback and perspectives to be incorporated into the team's work.</li> <li>Having researchers in residence from other disciplines facilitates an interdisciplinary exchange of ideas in light of   interdisciplinary issues.</li> <li>Research outcomes enable knowledge exchange between the scientific community and public organizations, in the   Netherlands and abroad.</li> </ul>"},{"location":"adrs/0011-researcher-in-residence/#decision","title":"Decision","text":"<p>We have decided to include a researcher in residence as a member of our team.</p> <p>The researcher in residence takes the following form:</p> <ul> <li>They join and participate in refinement meetings and other meetings of relevance.</li> <li>They share their reflections and present their (interim) research findings.</li> <li>They are provided access to the communication channel of the team (Mattermost).</li> <li>They meet with a contact person bi-weekly to discuss questions and relevant progress and findings.</li> <li>The are independent as they are employed and financed by their respective university.</li> <li>The results of their research, and thus processed data, are published in an academic journal.</li> </ul> <p>The following conditions apply to the researcher in residence.</p> <ul> <li>The research is able to access and analyze documents relevant to the research (ex. Notes/minutes taken). These   documents are submitted to a member of the team for review prior to being processed.</li> <li>Any data collected and analyzed via interviews is done on the basis of informed consent.</li> <li>The data collected is not shared with other parties and is handled ethically by the researcher.</li> <li>No information, aggregation, or summary of information from the communication channel of the team (Mattermost) is   collected, processed, or analyzed by the researcher.</li> </ul>"},{"location":"adrs/0011-researcher-in-residence/#risks","title":"Risks","text":"<p>Risks around a potential chilling effect (team members not feeling free to express themselves) are mitigated by the conditions we impose. In light of aforementioned form and conditions above, we see no further significant risks.</p>"},{"location":"adrs/0011-researcher-in-residence/#consequences","title":"Consequences","text":"<p>Including a researcher in residence makes it easier for them to conduct research within both the team and the wider organization where the AI validation team operates. This benefits the quality of the research findings and the feedback provided to the team and organization.</p>"},{"location":"adrs/0012-dictionary-for-spelling/","title":"ADR-0012 Dictionary for spelling","text":""},{"location":"adrs/0012-dictionary-for-spelling/#adr-0012-dictionary-for-spelling","title":"ADR-0012 Dictionary for spelling","text":""},{"location":"adrs/0012-dictionary-for-spelling/#context","title":"Context","text":"<p>We use English as language in some of our external communications, like on GitHub. We noticed that among different documents certain words are spelled correctly but differently, depending on the author or dictionary used. Also there are occasional typos which can cause distraction and don't meet professional standards.</p>"},{"location":"adrs/0012-dictionary-for-spelling/#assumptions","title":"Assumptions","text":"<p>Standardizing the used dictionary avoids discussion on spelling and makes documents consistent. Eliminating typos contributes to professional, credible and unambiguous documents.</p> <p>Using a dictionary in a pre-commit hook will prevent commits being made with obvious spelling issues.</p>"},{"location":"adrs/0012-dictionary-for-spelling/#decision","title":"Decision","text":"<p>We will use the U.S. English spelling dictionary.</p>"},{"location":"adrs/0012-dictionary-for-spelling/#risks","title":"Risks","text":"<p>It may slow down committing large files.</p>"},{"location":"adrs/0012-dictionary-for-spelling/#consequences","title":"Consequences","text":"<p>Documents will all use the same dictionary for spelling and will not contain typos.</p>"},{"location":"adrs/0013-date-time-representation/","title":"ADR-0013 Date Time Representation: ISO 8601","text":""},{"location":"adrs/0013-date-time-representation/#adr-0013-date-time-representation-iso-8601","title":"ADR-0013 Date Time Representation: ISO 8601","text":""},{"location":"adrs/0013-date-time-representation/#context","title":"Context","text":"<p>In our software development projects, we have encountered ambiguity related to the representation of dates and times, particularly when dealing with time zones. The lack of a standardized approach has led to discussions and possibly ambiguity when interpreting timestamps within our applications.</p>"},{"location":"adrs/0013-date-time-representation/#assumptions","title":"Assumptions","text":"<p>Standardizing the representation of dates and times will improve clarity and precision in our application's logic and user interfaces.</p> <p>ISO 8601 format is better human-readable than other formats such as unix timestamps.</p>"},{"location":"adrs/0013-date-time-representation/#decision","title":"Decision","text":"<p>We adopt ISO 8601 with timezone notation, preferably in UTC (<code>Z</code>), as the standard method for representing dates and times in our software projects, replacing the usage of Unix timestamps or any other formats or timezones. We use both dashes (<code>-</code>) and colons (<code>:</code>).</p> <p>We store date and time as: <code>2024-04-16T16:48:14Z</code> (preferably with <code>Z</code> as timezone, representing UTC)</p> <p>We store dates as <code>2024-04-16</code>.</p> <p>Only when capturing client events we may want to choose to store the client timezone instead of UTC.</p> <p>When rendering a date and time in a user interface, we may want to localize the date and time for the appropriate timezone.</p>"},{"location":"adrs/0013-date-time-representation/#risks","title":"Risks","text":"<p>Increased storage space: ISO 8601 representations can be longer than other formats, leading to potential increases in storage requirements, especially when dealing with large datasets.</p>"},{"location":"adrs/0013-date-time-representation/#consequences","title":"Consequences","text":"<p>A single ISO 8601 with UTC timezone provides a clear and unambiguous way to represent dates and times. Its format is easily recognizable and eliminates the need for interpretation. For example: <code>2024-04-15T10:00:00Z</code> can easily be understood without needing to parse it using a library.</p> <p>We will need to regularly convert from localized time to UTC and back when capturing, storing, and rendering dates and times.</p>"},{"location":"adrs/0013-date-time-representation/#more-information","title":"More Information","text":"<p>ISO 8601 is an internationally recognized standard endorsed by the International Organization for Standardization (ISO). Its adoption offers numerous benefits, including improved clarity, global accessibility, and future-proofing of systems and applications.</p> <p>For further reading on ISO 8601:</p> <ul> <li>Forum Standaardisatie - Datum en Tijd</li> <li>ISO 8601-1:2019 - Date and Time Format</li> <li>ISO 8601 - Wikipedia</li> </ul>"},{"location":"adrs/0014-written-language/","title":"ADR-0014 Written Language","text":""},{"location":"adrs/0014-written-language/#adr-0014-written-language","title":"ADR-0014 Written Language","text":""},{"location":"adrs/0014-written-language/#context","title":"Context","text":"<p>In order to expand our reach and foster international collaboration in the field of AI Validation, we have decided to conduct all communication in English on public platforms such as GitHub. This decision aims to facilitate better understanding and participation from our global colleagues. However, within the Government of the Netherlands, the norm is to communicate in Dutch for internal purposes. This ADR will provide guidelines on which language to use for different types of communications.</p>"},{"location":"adrs/0014-written-language/#assumptions","title":"Assumptions","text":"<p>There is no requirement to use Dutch as the primary language for all our activities while working for the Government of the Netherlands. More information can be found in the More Information section.</p>"},{"location":"adrs/0014-written-language/#decision","title":"Decision","text":"<p>The following channels will utilize English:</p> <ul> <li>GitHub projects</li> <li>GitHub repository</li> <li>Email to international partners</li> </ul> <p>The primary language for the following channels will be Dutch:</p> <ul> <li>Mattermost (internal collaboration tool)</li> <li>Emails to internal parties</li> <li>Official internal documents like memo's or notes to the house of representatives</li> <li>Guides for Dutch users on how to use the tools</li> <li>UI for the tools we will make</li> </ul>"},{"location":"adrs/0014-written-language/#risks","title":"Risks","text":"<p>Dutch-only developers will have a harder time following along with the progression of our team on both the code on GitHub as our Project Management.</p>"},{"location":"adrs/0014-written-language/#consequences","title":"Consequences","text":"<ul> <li>All tickets and issues will be written in English on GitHub projects.</li> <li>Code reviews will be written in English.</li> <li>Comments in the code and commit messages will be written in English.</li> <li>Documentation of the tools will be written in both Dutch and English.</li> </ul>"},{"location":"adrs/0014-written-language/#more-information","title":"More Information","text":"<p>Although many attempts by previous cabinets, Dutch is not the official language in the Netherlands according to the Dutch constitution. See the following Nederlandse Grondwet website.</p> <p>According to the website of the Government of the Netherlands the Dutch language is the official recognized language. This means that in combination with the law <code>Algemene wet bestuursrecht</code> on wetten.overheid.nl governing bodies and their employees need to communicate in Dutch unless stated differently elsewhere. It is stated in article 2:6 of the law that communicating in another language than Dutch is permitted if the goal of communicating in another language than Dutch is sufficiently justified and if other parties are not effected disproportionately by the usage of another language.</p>"},{"location":"adrs/0016-government-cloud-comparison/","title":"ADR-0016 Government Cloud Comparison","text":""},{"location":"adrs/0016-government-cloud-comparison/#adr-0016-government-cloud-comparison","title":"ADR-0016 Government Cloud Comparison","text":""},{"location":"adrs/0016-government-cloud-comparison/#context","title":"Context","text":"<p>Right now we have a few organizations (Logius, SSC-ICT, ODC-Noord, Tender process, and Digilab, etc...) offering IT infrastructure. This ADR will give an overview of what these different organizations are offering as well as make a decision for the AI Validation team on which infrastructure provider we will focus.</p>"},{"location":"adrs/0016-government-cloud-comparison/#descriptions-and-comparison","title":"Descriptions and comparison","text":"<ul> <li>SSC-ICT<ul> <li>Description:<ul> <li>SSC-ICT is an ICT service provider for some ministries of the government of the Netherlands. In the   service catalogue of 2024   no mention of Kubernetes is in the document. They are specialized in workplace management but through an   NSK(not standard client request) extra services could be provided by them.</li> </ul> </li> <li>Pros:<ul> <li>The integration with the RON (Rijksoverheid Network) is managed well because that is a service that SSC-ICT also manages.</li> </ul> </li> <li>Cons:<ul> <li>They are known to be very bureaucratic, a standard NSK can take up at least half a year and then still you don't have what you want.</li> </ul> </li> </ul> </li> <li>Standaard Platform (Logius)<ul> <li>Description:<ul> <li>The standard Platform of Logius will provide an Openshift Kubernetes namespace or cluster for you</li> </ul> </li> <li>Pros:<ul> <li>High availability is possible with an SLA (so production ready)</li> <li>More separation of concerns if you want to have a separate cluster</li> <li>GitLab is included; therefore easy CI/CD</li> <li>Convenient connection with the Centraal Aansluitpunt of Logius</li> </ul> </li> <li>Cons:<ul> <li>It is not vanilla Kubernetes</li> <li>They do not want to be a cloud service provider, they do provide GitLab and PostgreSQL but not Keycloak because they want to minimize the services they provide (focus should be on the platform).</li> </ul> </li> </ul> </li> <li>ODC-Noord<ul> <li>Description:<ul> <li>ODC-Noord provides multiple services, on one hand it can provide:         - Platform as a Service, with this service you can set-up Virtual machines with specific open source software packages. However, this is not a scalable service, as you are limited to quotas you have on a project and limits of the virtual instance.         - Another service is Infrastructure as a Service, here you can set-up anything you want on Openshift.         - There are several specialized services on ODC-Noord as well for development street or data science but these are not suitable for hosting a custom application.</li> </ul> </li> <li>Pros:<ul> <li>It is another governmental party which makes communication and commitment easier.</li> </ul> </li> <li>Cons:<ul> <li>ODC-Noord stated that they will not invest in GPUs, which would limit our Machine Learning Jobs potential.</li> <li>The Platform as a Service is less scalable then we would like to see.</li> </ul> </li> </ul> </li> <li>Digilab<ul> <li>Description:<ul> <li>Digilab will provide an Openshift Kubernetes namespace for you, but also managed services like Mattermost.</li> </ul> </li> <li>Pros:<ul> <li>The platform is made such based on the vision of Common Ground, and thus to standardize cloud hosting through Haven for all Dutch municipalities. This standardization improves on integration later on.</li> <li>It is vanilla Kubernetes</li> </ul> </li> <li>Cons:</li> </ul> </li> <li>Tender Process Aanbestedingswet<ul> <li>Description:<ul> <li>If you don't want to make use of the governmental parties stated above you could go to the free market to provide infrastructure for you. As the government cannot simply find a party to implement this for them, you need to go through a tender process as described in the law stated above in the title.</li> </ul> </li> <li>Pros:<ul> <li>The process of acquiring this is open and transparent for everybody.</li> </ul> </li> <li>Cons:<ul> <li>Takes a while as generally just like with SSC-ICT you need to write a whole set of documents to specify what you exactly want and you cannot change this in the meantime.</li> </ul> </li> </ul> </li> <li>SLM Rijk<ul> <li>Description:<ul> <li>The Rijksoverheid has made Strategic Delivery Agreement that with certain restrictions public cloud providers can be used by the Dutch Government.</li> </ul> </li> <li>Pros:<ul> <li>It is very easy to set-up infrastructure with the big international cloud providers.</li> </ul> </li> <li>Cons:<ul> <li>With our team we decided that we prefer open source solutions. So if we use some managed solutions of the big cloud providers we would not be following our principles.</li> </ul> </li> </ul> </li> <li>DICTU<ul> <li>Description:<ul> <li>DICTU is a governmental party which can will develop custom managed solutions on their own cloud, DICTU is part of the Ministry of Economic Affairs but is also available for other ministries. It is rumoured that just like other parties it could provide just some Kubernetes namespaces for you.</li> </ul> </li> <li>Pros:<ul> <li>They have an impressive track record and can deliver production ict services well.</li> </ul> </li> <li>Cons:<ul> <li>You need to do stakeholder management if you make use of their services instead of changing the infrastructure yourself.</li> </ul> </li> </ul> </li> <li>ICTU<ul> <li>Description:<ul> <li>ICTU is like DICTU also a governmental party, but then exists by law instead of under a ministry.</li> </ul> </li> <li>Pros:<ul> <li>They have an impressive track record and can deliver production ict services well.</li> </ul> </li> <li>Cons:<ul> <li>You need to do stakeholder management if you make use of their services instead of changing the infrastructure yourself.</li> </ul> </li> </ul> </li> </ul> <p>Please see the following picture for an overview of the providers in relation to what they can provide, currently we are heavily searching in the realm of unmanaged infrastructure, as we want this to manage ourselves.</p> <p></p>"},{"location":"adrs/0016-government-cloud-comparison/#decision","title":"Decision","text":"<p>For our infrastructure provider we decided to go with Digilab as the main source, as they can provide us with a Kubernetes namespace and are a reliable and convenient partner as we work closely with them.</p>"},{"location":"adrs/0016-government-cloud-comparison/#risks","title":"Risks","text":"<p>Certain choices are made for us if we make use of the Kubernetes namespace of Digilab, for example that we need to make use of Flux for our CI/CD pipeline.</p>"},{"location":"adrs/0016-government-cloud-comparison/#extra-information","title":"Extra information","text":"<ul> <li>Standaard Platform<ul> <li>Internal Document</li> </ul> </li> </ul>"},{"location":"projects/algorithm-reporting-standard/","title":"Algorithm Reporting Standard","text":""},{"location":"projects/algorithm-reporting-standard/#algorithm-reporting-standard","title":"Algorithm Reporting Standard","text":"<p>For the Algorithm Management Toolkit (AMT) we were looking for a standardized way to report on algorithmic systems. Inspired by Model Cards for Model Reporting and Papers with Code Model Index the Algorithm Reporting Standard extends the Hugging Face model card metadata specification to allow for:</p> <ol> <li>More fine-grained information on performance metrics.</li> <li>Capturing additional measurements on fairness and bias, which can be partitioned into bar plot like    measurements (such as mean absolute SHAP values) and graph plot like measurements (such as partial dependence).</li> <li>Capturing assessments (such as    IAMA    and ALTAI).</li> </ol> <p>More information about the Algorithm Reporting Standard can be found on the GitHub repository github.com/MinBZK/algorithm-reporting-standard. Here you can also find information about the definition of the System Card which contains Model Cards and Assessment Cards.</p> <p>Algorithm Reporting Standard on GitHUB</p>"},{"location":"projects/amt/","title":"Algorithm Management Toolkit (AMT)","text":""},{"location":"projects/amt/#algorithm-management-toolkit-amt","title":"Algorithm Management Toolkit (AMT)","text":"<p>The Algorithm Management Toolkit (AMT) aims to enhance transparency and governance throughout the entire lifecycle of algorithmic systems. By generating standardized reports, AMT provides a comprehensive view of both technical details and descriptive information, including regulatory assessments, from development to deployment and beyond. This continuous approach promotes accountability, oversight, and collaboration, ensuring that both models and data remain transparent, controlled, and validated over time. The definition for an algorithm is derived from the Algoritmeregister.</p> <p>The requirements and instruments are dictated by the Algoritmekader. The Algorithm Reporting Standard is used to store the information in a structured way. The final result of the AMT is kind of a book keeping platform for algorithms. A platform where you can keep track of System, Model and Assessment Cards with performance metrics, (regulatory) assessments on the system where the specific algorithm resides, and descriptive  information about the system.</p> <p>Try out the Algorithm Management Toolkit AMT project on GitHUB</p>"},{"location":"projects/amt/adrs/0001-adrs/","title":"AMT-0001 ADRs","text":""},{"location":"projects/amt/adrs/0001-adrs/#amt-0001-adrs","title":"AMT-0001 ADRs","text":""},{"location":"projects/amt/adrs/0001-adrs/#context","title":"Context","text":"<p>In modern software development practices, the use of Architecture Decision Records (ADRs) has become increasingly common. ADRs are documents that capture important architectural decisions made during the development process. These decisions play a crucial role in guiding the development team and ensuring consistency and coherence in the architecture of the software system.</p>"},{"location":"projects/amt/adrs/0001-adrs/#assumptions","title":"Assumptions","text":"<ol> <li>ADRs provide a structured way to document and communicate architectural decisions.</li> <li>Publishing ADRs publicly fosters transparency and facilitates collaboration among team members and stakeholders.</li> <li>ADRs help in onboarding new team members by providing insights into past decisions and their rationale.</li> </ol>"},{"location":"projects/amt/adrs/0001-adrs/#decision","title":"Decision","text":"<p>We will utilize ADRs in this project repository and communicate architectural decisions effectively. Furthermore, we will publish these ADRs publicly to promote transparency and facilitate collaboration.</p>"},{"location":"projects/amt/adrs/0001-adrs/#template","title":"Template","text":"<p>Use the template below to add an ADR:</p> <pre><code># AMT-XXXX Title\n\n## Context\n\nWhat is the issue that we're seeing that is motivating this decision or change?\n\n## Assumptions\n\nAnything that could cause problems if untrue now or later. (optional)\n\n## Decision\n\nWhat is the change that we're proposing and/or doing?\n\n## Risks\n\nAnything that could cause malfunction, delay, or other negative impacts. (optional)\n\n## Consequences\n\nWhat becomes easier or more difficult to do because of this change?\n\n## More Information\n\nProvide additional evidence/confidence for the decision outcome\nLinks to other decisions and resources might here appear as well. (optional)\n</code></pre>"},{"location":"projects/amt/adrs/0002-amt-reporting-standard/","title":"AMT-0002 AMT Reporting Standard","text":""},{"location":"projects/amt/adrs/0002-amt-reporting-standard/#amt-0002-amt-reporting-standard","title":"AMT-0002 AMT Reporting Standard","text":""},{"location":"projects/amt/adrs/0002-amt-reporting-standard/#context","title":"Context","text":"<p>The AMT Reporting Standard proposes a standardized way of capturing information of ML-models and systems.</p>"},{"location":"projects/amt/adrs/0002-amt-reporting-standard/#assumptions","title":"Assumptions","text":"<p>There is no existing standard of capturing all relevant information on ML-models that also includes fairness and bias tests and regulatory assessments.</p> <p>A widely used implementation for Model Cards for Model Reporting is given by the Hugging Face Model Card metadata specification, which in turn is based on Papers with Code Model Index. This implementation does not capture sufficient details about metrics and does not include measurements from technical tests on bias and fairness or regulatory assessments.</p>"},{"location":"projects/amt/adrs/0002-amt-reporting-standard/#decision","title":"Decision","text":"<p>We decided to implement a custom reporting standard. Our reporting standard can be split up into three elements.</p> <ol> <li>System Card, containing information about a group of ML-models which accomplish a specific task. A System Card can refer to multiple Model Cards, either a Model Card specified by the AMT Reporting Standard, or any other model card. A System Card can refer to multiple Assessment Cards.</li> <li>Model Card, containing information about a specific ML-model.</li> <li>Assessment Card, containing information about a regulatory assessment.</li> </ol> <p>We were heavily inspired by the Hugging Face Model Card metadata specification, which we essentially extended to allow for:</p> <ol> <li>More fine-grained information on performance metrics.</li> <li>Capturing additional measurements on fairness and bias.</li> <li>Capturing regulatory assessments.</li> </ol> <p>The extension is not strict, meaning that there the AMT Reporting Standard is not a valid Hugging Face metadata specification. The reason for this is that some fields in the Hugging Face standard are too much intertwined with the Hugging Face ecosystem and it would not be logical for us to couple our implementation this tightly to Hugging Face.</p>"},{"location":"projects/amt/adrs/0002-amt-reporting-standard/#risks","title":"Risks","text":"<p>The AMT Reporting Standard is not fully backwards compatible with the Hugging Face Model Card metadata specification. If in the future the Hugging Face Model Card metadata specification becomes a standard, we might need to revise the AMT standard.</p>"},{"location":"projects/amt/adrs/0002-amt-reporting-standard/#consequences","title":"Consequences","text":"<p>The AMT Reporting Standard allows us to capture relevant information on model performance, bias and fairness and regulatory assessments in a standardized way.</p>"},{"location":"projects/amt/adrs/0003-amt-tool/","title":"AMT-0003 Tool for Managing Algorithms","text":""},{"location":"projects/amt/adrs/0003-amt-tool/#amt-0003-tool-for-managing-algorithms","title":"AMT-0003 Tool for Managing Algorithms","text":""},{"location":"projects/amt/adrs/0003-amt-tool/#context","title":"Context","text":"<p>We are considering tooling for organizations to get more grip on their algorithms. Tooling for, for instance bias and fairness tests, and assessments (like IAMA).</p> <p>Transparency, we think, can be fostered by sharing reports from such a tool in a standardized way.</p> <p>There are several existing open source tools which we have assessed. Some support only assessments, others already combine more features and can generate a report. There is however no tool that supports all the requirements we have.</p> <p>These are our main requirements of our tool:</p> <ul> <li>it offers a one-stop shop for all aspects of the project for all stakeholders for all tasks.</li> <li>it supports a workflow to track different stages of the project, it should support lifecycle management.</li> <li>it can run many technical tests on a model.</li> <li>it supports filling out assessments.</li> <li>it supports capturing discussion and collaboration around technical tests and assessments,   with features like f.e. mentions, (email) notifications and status updates.</li> <li>it offers UI access to the above requirements.</li> <li>it can save results to a system card (or cards supported by system cards, like model, metrics and assessment).</li> <li>it can commit the different cards to a VCS, such as git, to allow for an audit trail.</li> <li>it supports a multilingual user interface, initially in Dutch and in the future Frisian.</li> <li>it supports multiple projects with one or multiple algorithms.</li> </ul>"},{"location":"projects/amt/adrs/0003-amt-tool/#assumptions","title":"Assumptions","text":"<ul> <li>Collaborating or extending another project will not give us the tool we are looking for.</li> <li>We can reuse certain components, like the   plugins from AIVerify, or existing libraries,   for technical tests.</li> <li>The tool will use a design based on loose coupled modules. This can be done by scanning directories,   to gather modules that implement a certain interface.</li> <li>Plugins will have to implement an interface to be picked up by the system.</li> <li>We can, to some extend, re-use the already existing POCs or findings from these POCs.</li> </ul>"},{"location":"projects/amt/adrs/0003-amt-tool/#decision","title":"Decision","text":"<p>We will build our own solution. Where possible this solution should be able to re-use certain components of other related open-source projects.</p>"},{"location":"projects/amt/adrs/0003-amt-tool/#risks","title":"Risks","text":"<ul> <li>It is a lot of work to create our own tool.</li> <li>We may not have sufficient knowledge of existing technical tests to incorporate them successfully.</li> <li>We may struggle to get uptake of the tool if we are not aligned with envisioned users of the tool.</li> </ul>"},{"location":"projects/amt/adrs/0003-amt-tool/#consequences","title":"Consequences","text":"<p>We can develop a solution that is tailored to the needs of our stakeholders.</p>"},{"location":"projects/amt/adrs/0004-software-stack/","title":"AMT-0004 Software Stack for AMT","text":""},{"location":"projects/amt/adrs/0004-software-stack/#amt-0004-software-stack-for-amt","title":"AMT-0004 Software Stack for AMT","text":""},{"location":"projects/amt/adrs/0004-software-stack/#context","title":"Context","text":"<p>For building our own AMT solution, we need to choose a software stack. During our earlier POCs and market research, we gathered insight and information on technologies to use and which not to use.</p> <p>During further discussions and brainstorm sessions, a software stack was chosen that accommodates our needs best.</p> <p>While more fine grained requirements are listed elsewhere, some key requirements are:</p> <ul> <li>The tool is locally runnable with docker.</li> <li>The tool is runnable as user as a local Docker solution.</li> <li>The tool is runnable on a cloud platform based on Kubernetes.</li> <li>The tool supports multiple organizations, teams and projects.</li> <li>The tool supports Oauth2.</li> </ul>"},{"location":"projects/amt/adrs/0004-software-stack/#assumptions","title":"Assumptions","text":"<p>We stick to suitable programming languages. As most AI related tooling is written in Python, this language is the logical choice for our development as well.</p> <p>Currently, we do not see the need for a separate web GUI framework. it is preferred to bundle backend and frontend in one solution.</p> <p>As part of a Dutch government organization, we need to adhere to all Dutch laws and standards, like:</p> <ul> <li>Digitoegankelijk</li> <li>WCAG Guidelines</li> <li>Forum Standaardisatie</li> </ul>"},{"location":"projects/amt/adrs/0004-software-stack/#decision","title":"Decision","text":""},{"location":"projects/amt/adrs/0004-software-stack/#programming-language","title":"Programming language","text":"<p>We will support the latest 3 minor version of Python v3 as programming language and Poetry for dependency management.</p>"},{"location":"projects/amt/adrs/0004-software-stack/#backend","title":"Backend","text":"<p>The Python backend will use the following key dependencies:</p> <ul> <li>Granian as HTTP server.</li> <li>Pydantic for data validation.</li> <li>FastAPI for REST/API/HTML communication.</li> <li>Jinja2 for templating.</li> <li>i18n Extension for multilingual support with gettext or Babel.</li> </ul>"},{"location":"projects/amt/adrs/0004-software-stack/#frontend","title":"Frontend","text":"<p>We will use server-side rendering of HTML based on HTMX. For our main styling, we use Rijkshuisstijl. This is implemented by using design tokens, so that other organizations can use their own styling when using our tools by linking their own tokens.</p> <p>When available, we use components from the NL Design System. If a component is not available, we will build it ourselves and contribute it to the NL Design System. We will publish the components that we use in our Storybook, which is hosted on the BZK GitHub repository.</p>"},{"location":"projects/amt/adrs/0004-software-stack/#testing","title":"Testing","text":"<p>We will use pytest for unit-testing and VCRPY and Playwright for module and integration tests.</p>"},{"location":"projects/amt/adrs/0004-software-stack/#database","title":"Database","text":"<p>We will use SQLModel or SQL Alchemy with SQLite for development and postgreSQL for production.</p>"},{"location":"projects/amt/adrs/0004-software-stack/#risks","title":"Risks","text":"<p>As HTMX is relatively more limited than other UI frameworks, it may lack features we require but did not anticipate.</p>"},{"location":"projects/amt/adrs/0004-software-stack/#consequences","title":"Consequences","text":"<p>We have clarity about the tools to use and develop our AMT tool.</p>"},{"location":"projects/amt/adrs/0005-ai-verify-technical-tests/","title":"AMT-0005 Add support to run technical tests via AI Verify","text":""},{"location":"projects/amt/adrs/0005-ai-verify-technical-tests/#amt-0005-add-support-to-run-technical-tests-via-ai-verify","title":"AMT-0005 Add support to run technical tests via AI Verify","text":""},{"location":"projects/amt/adrs/0005-ai-verify-technical-tests/#context","title":"Context","text":"<p>The AI Verify project is set up in a modular way, and the technical tests is one of the modules. The AI Verify team is developing a feature which makes it possible to run the technical tests using an API: a Python library with a method to run a test and providing the required configuration; for example, which  model and dataset to use and some test specific configuration.</p> <p>The result of the test are returned in a JSON format, which can be processed in any way we please, like writing it to a file or System Card or store it in a database.</p>"},{"location":"projects/amt/adrs/0005-ai-verify-technical-tests/#pros","title":"Pros","text":"<ul> <li>We have several technical tests we can use of the shelf, like SHAP, ALE, or Fairness metrics.</li> <li>Tests are set up in a generic way using interfaces which allows others, like ourselves, to create and add  their own plugins.</li> <li>Loading models, pipelines and data is done through the AI Verify toolkit, which not only streamlines this process  but also performs validation and support checks.</li> <li>We benefit from new tests being added in the future.</li> </ul>"},{"location":"projects/amt/adrs/0005-ai-verify-technical-tests/#cons","title":"Cons","text":"<ul> <li>The outcome of an AI Verify test depends on the implementation chosen by the developer of the  plugin. This means there is no control or flexibility over what data (metrics, logs etc.) is  included in the output.</li> <li>Adding our own plugins may require adding AI Verify frontend components we don't use ourselves.</li> <li>We are dependent on the AI Verify ecosystem for supported models and data formats. However, they are  (like us) planning to expand model support to also include ONNX and we can contribute ourselves to support  a wider range of models and data formats.</li> <li>Running pipeline tests requires familiarity with the toolkit's pipeline handling mechanisms.</li> </ul>"},{"location":"projects/amt/adrs/0005-ai-verify-technical-tests/#assumptions","title":"Assumptions","text":"<ul> <li>We can wrap the API and other AI Verify requirements in a Docker image.</li> <li>We can run the Docker image independently where we only have to provide the model, datasets and other  required configuration to run a test.</li> <li>We can monitor the progress of a test in our AMT tool.</li> <li>We can process the results of a test in our AMT tool.</li> </ul>"},{"location":"projects/amt/adrs/0005-ai-verify-technical-tests/#decision","title":"Decision","text":"<p>Our technical tests will include, but may extend beyond, those offered by AI Verify.</p>"},{"location":"projects/amt/adrs/0005-ai-verify-technical-tests/#risks","title":"Risks","text":"<p>The tests we use from AI Verify are tied to the AI Verify ecosystem. So it uses their (core) modules to load models and datasets. Adding support for other models or data formats, like models written in R, has to be done in the AI Verify core.</p>"},{"location":"projects/amt/adrs/0005-ai-verify-technical-tests/#consequences","title":"Consequences","text":"<p>We have a set of technical tests we can integrate in the AMT tool.</p>"},{"location":"projects/amt/adrs/0006-extend-system-card-EU-AI-Act/","title":"AMT-0006 Include EU AI Act into System Card","text":""},{"location":"projects/amt/adrs/0006-extend-system-card-EU-AI-Act/#amt-0006-include-eu-ai-act-into-system-card","title":"AMT-0006 Include EU AI Act into System Card","text":""},{"location":"projects/amt/adrs/0006-extend-system-card-EU-AI-Act/#context","title":"Context","text":"<p>The European Union AI Act represents a landmark regulatory framework aimed at ensuring the safe and ethical development and deployment of artificial intelligence technologies within the EU. It defines different policies and requirements for AI systems based on their risk levels, from minimal to unacceptable, to mitigate potential harms. Only for high-risk AI systems, an extended form of documentation is required, including technical documentation. This technical documentation consists of a general description of the AI system and a more detailed, in-depth description (including risk-management, monitoring, etc.).</p> <p>To ensure that AI systems can be effectively audited, we aim to create a separate instrument called 'technical documentation for high-risk AI systems'. This will allow developers to easily extract and auditors to readily assess all necessary information for the technical documentation.</p> <p>The RegCheck AI tool published by Hugging Face, checks model cards for compliance with the EU AI Act. However, this prototype tool is research work and not a commercial or legal product. Furthermore, because we use a modified model card setup, the performance may be less reliable.</p>"},{"location":"projects/amt/adrs/0006-extend-system-card-EU-AI-Act/#assumptions","title":"Assumptions","text":"<ul> <li>There is no existing standard for including information on the EU AI Act for high-risk AI systems into a system card.</li> <li>We assume that the EU AI Act is about a whole AI system, that can include multiple AI models.</li> </ul>"},{"location":"projects/amt/adrs/0006-extend-system-card-EU-AI-Act/#decision","title":"Decision","text":"<ul> <li>We include the general description cases of the EU AI Act for high-risk systems into the system card directly.</li> <li>We create a separate instrument including the complete technical documentation into the task registry.</li> </ul>"},{"location":"projects/amt/adrs/0006-extend-system-card-EU-AI-Act/#risks","title":"Risks","text":"<ul> <li>In the case of a high-risk algorithm, the general information can be found in two places, the system card itself and in the assessment card.</li> <li>The system card may become too elaborate when we include the general description fields.</li> </ul>"},{"location":"projects/amt/adrs/0006-extend-system-card-EU-AI-Act/#consequences","title":"Consequences","text":"<p>The extended system card and proposed instrument will facilitate the documentation of information in accordance with the EU AI Act using the AMT tool.</p>"},{"location":"projects/amt/adrs/0007-front-end-components-implementation/","title":"AMT-0007 Front-end components implementation","text":""},{"location":"projects/amt/adrs/0007-front-end-components-implementation/#amt-0007-front-end-components-implementation","title":"AMT-0007 Front-end components implementation","text":""},{"location":"projects/amt/adrs/0007-front-end-components-implementation/#context","title":"Context","text":"<p>We will implement the NL Design System to ensure consistency, accessibility, and efficiency in our user interface development. This decision is motivated by the need to align with accessibility standards and best practices. Ensuring that our products are intuitive, cohesive, and maintain a high standard of quality. By leveraging the NL Design System, we will streamline our design process and collaborate with other governmental institutions.</p>"},{"location":"projects/amt/adrs/0007-front-end-components-implementation/#assumptions","title":"Assumptions","text":"<ul> <li>The NL Design System will continue to evolve and remain supported.</li> <li>Our team has the capacity and expertise to contribute to the NL Design System when needed.</li> <li>The existing components in the NL Design System will cover the majority of our design needs.</li> </ul>"},{"location":"projects/amt/adrs/0007-front-end-components-implementation/#decision","title":"Decision","text":"<p>We will adopt the NL Design System as the foundation for our GUI implementation. For any special requirements not covered by the system, we will develop our own components and contribute them back to the NL Design System community where applicable. We will not adopt our own NL Design System but rather always contribute to the existing ones.</p> <p>We make use of the following NL Design Systems: ROOS Design System from RVO, Utrecht Design System from the municipality of Utrecht. In the future, we will also align with the Rijkshuisstijl community, ensuring that our contributions and customizations adhere to broader governmental design standards.</p>"},{"location":"projects/amt/adrs/0007-front-end-components-implementation/#risks","title":"Risks","text":"<ul> <li>The NL Design System might not evolve quickly enough to meet all our future needs,   leading to potential delays in development.</li> <li>Contributing back to the NL Design System might require additional resources and   could introduce complexities in managing our own custom components.</li> <li>Dependence on external systems and communities might pose a risk if their priorities   shift or if there is a lack of support.</li> </ul>"},{"location":"projects/amt/adrs/0007-front-end-components-implementation/#consequences","title":"Consequences","text":""},{"location":"projects/amt/adrs/0007-front-end-components-implementation/#positive","title":"Positive","text":"<ul> <li>Consistency: Our products will benefit from a consistent look and feel,   in line with governmental standards.</li> <li>Efficiency: Reusing existing components will accelerate development and reduce redundancy.</li> <li>Community engagement: By contributing to the NL Design System, we enhance our standing within   the design community and promote shared innovation.</li> </ul>"},{"location":"projects/amt/adrs/0007-front-end-components-implementation/#negative","title":"Negative","text":"<ul> <li>Customization complexity: Developing and maintaining custom components might increase our design and development workload.</li> <li>Dependency: Our design system will be partially dependent on external frameworks and community  developments, which could introduce unforeseen challenges.</li> </ul>"},{"location":"projects/amt/adrs/0007-front-end-components-implementation/#more-information","title":"More Information","text":"<ul> <li>ROOS Design System - The design system developed by RVO,   which will serve as an initial reference.</li> <li>Rijkshuisstijl Community - The broader   community we plan to engage with in the future.</li> <li>NL Design System official documentation - The NL Design System community, documentation   and tools.</li> </ul>"},{"location":"projects/amt/adrs/0008-systemcard-storage/","title":"AMT-0008 System card Storage","text":""},{"location":"projects/amt/adrs/0008-systemcard-storage/#amt-0008-system-card-storage","title":"AMT-0008 System card Storage","text":""},{"location":"projects/amt/adrs/0008-systemcard-storage/#context","title":"Context","text":"<p>By default, Kubernetes pods use ephemeral storage, which is tied to the pod's lifecycle. When the pod terminates or restarts, all data is lost. The <code>/tmp/</code> directory, being part of the system's temporary file storage, is cleared during reboots or pod restarts, resulting in the deletion of system_cards. Therefore, we need a different kind of storage to preserve the data.</p>"},{"location":"projects/amt/adrs/0008-systemcard-storage/#assumptions","title":"Assumptions","text":"<ul> <li>The system card data is small to moderate in size (up to 255MB), making it manageable to store in databases (in postgres as well as in  in SQLite).</li> <li>Tracking changes to the system card data over time is not a priority in the short term, but may become necessary in the future.</li> </ul>"},{"location":"projects/amt/adrs/0008-systemcard-storage/#decision","title":"Decision","text":"<p>The system card of an algorithm system is stored solely as a JSON blob in the projects table in Postgres, with no additional storage elsewhere.</p>"},{"location":"projects/amt/adrs/0008-systemcard-storage/#risks","title":"Risks","text":"<ul> <li>Data Overwrite: As the system card is overwritten with each update, it becomes difficult to track historical changes or revert to previous states.</li> <li>Scaling: As the project grows, managing larger JSON blobs may present performance challenges, particularly when handling complex queries.</li> <li>Collaboration: Collaborating on the system card content is more difficult, as the JSON format requires parsing and manual intervention for certain tasks.</li> <li>Limited Querying: While Postgres supports querying and indexing JSON fields, complex queries and data manipulations may be inefficient without proper indexing or further optimization.</li> </ul>"},{"location":"projects/amt/adrs/0008-systemcard-storage/#consequences","title":"Consequences","text":""},{"location":"projects/amt/adrs/0008-systemcard-storage/#positive","title":"Positive","text":"<ul> <li>Fast implementation: The solution is easy to set up, reducing the time to get the project operational.</li> <li>Future proof: This approach is designed with future scalability in mind. While system cards will initially be stored in Postgres as JSONB blobs, we anticipate migrating to a Git-based local or remote storage solution as the system evolves. Importantly, this initial decision allows for a seamless transition in the future, ensuring no obstacles to migration.</li> <li>Single source &amp; Fast access: Centralizing everything in a single Postgres database streamlines backups, reduces maintenance complexity, and ensures quick data access.</li> <li>Built-in permissions: Postgres provides built-in access control and security through its permission system.</li> </ul>"},{"location":"projects/amt/adrs/0008-systemcard-storage/#negative","title":"Negative","text":"<ul> <li>Data tracking: Changes to the system card are overwritten, making it difficult to maintain a history or audit trail.</li> <li>Complex queries: Complex queries can be inefficient and require custom parsing.</li> <li>Collaboration: Collaborating on the JSONB data is challenging due to its complex format and lack of version control.</li> <li>Scalability: As the JSONB blobs grow in size, the storage overhead and query performance may become significant issues.</li> <li>Not supported by SQLite: While SQLite supports JSON through its JSON1 extension, it does not support PostgreSQL's JSONB data type natively, which complicates local development and testing environments that rely on SQLite as a database backend.</li> </ul>"},{"location":"projects/amt/existing-tools/checklists/ai_assesment_tool_checklist/","title":"ALTAI","text":""},{"location":"projects/amt/existing-tools/checklists/ai_assesment_tool_checklist/#altai","title":"ALTAI","text":"<p>See the introduction. It is a discussion tool about AI Systems.</p>"},{"location":"projects/amt/existing-tools/checklists/ai_assesment_tool_checklist/#functionality","title":"Functionality","text":"Requirement Priority Fulfilled Comments The tool allows users to conduct technical tests on algorithms or models, including assessments of performance, bias, and fairness. To facilitate these tests, users can input relevant datasets, M 0 The tool only allows for discussions not technical tests The tool allows users to choose which tests to perform. M 0 See above The tool allows users to fill out questionnaires to conduct impact assessments for AI. For example IAMA or ALTAI. M 1 This is very well supported by the tool The tool can generate a human readable report. M 0.9 There is an export functionality for the outcomes of the assessment, it offers a print dialog The tools works with a standardized report format, that it can read, write, and update. M 0 This report cannot be re-imported in a different tool as it only exports to pdf The tool supports plugin functionality so additional tests can be added easily. S 0 Not applicable The tool allows to create custom reports based on components. S 0 The report cannot be customized by the user It is possible to add custom components for reports. S 0 See above The tool provides detailed logging, including tracking of different model versions, changes in impact assessments, and technical test results for individual runs. S 0.75 There is even for the users an extensive audit trail what happened to assessment, not different model versions The tool supports saving progress. S 1 Yes this is supported The tool can be used on an isolated system without an internet connection. S 1 Yes it can be ran locally or in a docker container without internet The tool offers options to discuss and document conversations. For example, to converse about technical tests or to collaborate on impact assessments. C 1 This is the main feature of the tool The tool operates with complete data privacy; it does not share any data or logging information. C 1 Stored locally in a mongoDB The tool allows extension of report formats functionality. C 0.5 It could be developed that we export to markdown instead of pdf, but right now it just prints the window as pdf The tool can be integrated in a CI/CD flow. C 0 It is an UI tool, so doesn't make sense in a CI/CD pipeline The tool can be offered as a (cloud) service where no local installation is required. C 1 We could host this tool for other parties to use It is possible to define and automate workflows for repetitive tasks. C 0 It is an UI tool The tool offers pre-built connectors or low-code/no-code integration options to simplify the integration process. C 0 No <p>total_score = 22.85</p>"},{"location":"projects/amt/existing-tools/checklists/ai_assesment_tool_checklist/#reliability","title":"Reliability","text":"Requirement Priority Fulfilled Comments The tool operates consistently and reliably, meaning it delivers the same expected results every time you use it. M 1 Yes The tool recovers automatically from common failures. S 1 The tool seems too do this The tool recovers from failures quickly, minimizing data loss, for example by automatically saving intermediate test progress results. S 1 The data is stored in mongoDB, so no data is lost The tool handles errors gracefully and informs users of any issues. S 1 If the email server is down the tool still operates The tool provides clear error messages and instructions for troubleshooting. S 0.8 Some errors are not very informative when you get them, but mostly email related are <p>total_score = 15.4</p>"},{"location":"projects/amt/existing-tools/checklists/ai_assesment_tool_checklist/#usability","title":"Usability","text":"Requirement Priority Fulfilled Comments The tool possess a clean, intuitive, and visually appealing UI that follows industry standards. S 1 Very clean UI The tool provides clear and consistent navigation, making it easy for users to find what they need. S 1 Compared to AIVerify the navigation is very intuitive (but it also has less features) The tool is responsive and provides instant feedback. S 1 Yes The user interface is multilingual and supports at least English. S 0.8 There is support for multilingual, but the assessments are not translated and needs to be translated by hand The tool offers keyboard shortcuts for efficient interaction. C 0 No The user interface can easily be translated into other languages. C 0.8 The buttons are automatically translated but not the assessment itself <p>total_score = 13</p>"},{"location":"projects/amt/existing-tools/checklists/ai_assesment_tool_checklist/#help-documentation","title":"Help &amp; Documentation","text":"Requirement Priority Fulfilled Comments The tool provides comprehensive online help documentation with searchable functionalities. S 0.1 There is little documentation, only the website and the github readme The tool offers context-sensitive help within the application. C 0 The icons are just very clear, would be nice to have a question mark at some places The online documentation includes video tutorials and training materials for ease of learning. C 0 There is no such documentation The project provides readily available customer support through various channels  (e.g., email, phone, online chat) to address user inquiries and troubleshoot issues. C 0.25 You can issue tickets on Github, no other way supported way <p>total_score = 0.55</p>"},{"location":"projects/amt/existing-tools/checklists/ai_assesment_tool_checklist/#performance-efficiency","title":"Performance Efficiency","text":"Requirement Priority Fulfilled Comments The tool operates efficiently and minimize resource utilization. M 1 The docker container is not so very big, also doesn't use much resources The tool responds to user actions instantly. M 1 There is instant feedback in the UI The tool is scalable to accommodate increased user base and data volume. S 1 As it runs on Docker, you can scale this on Kubernetes for multiple users <p>total_score = 11</p>"},{"location":"projects/amt/existing-tools/checklists/ai_assesment_tool_checklist/#maintainability","title":"Maintainability","text":"Requirement Priority Fulfilled Comments The tool is easy to modify and maintain. M 0.8 You need to be a bit aware of NextJS, then it is easy to maintain as it is not such a large tool The tool adheres to industry coding standards and best practices to ensure code quality and maintainability. M 0.8 The code looks well structured, they have deployments on github but I don't see any CI or pre-commit hooks The code is written in a common, widely adopted and supported and actively used and maintained programming language. M 1 NextJS is very common for frontend tools The project provides version control for code changes and rollback capabilities. M 1 The code is hosted on Github so yes The project is open source. M 1 see above It is possible to contribute to the source. S 1 It is possible, not many people have done this yet The system is modular, allowing for easy modification of individual components. S 0.6 Extra assessments can be appended to the system, but not in such a way that it supports multiple (different) assessments, but roles can be changed very easily Diagnostic tools are available to identify and troubleshoot issues. S 0.8 The standard NextJS tools to troubleshoot, but not many tests <p>total_score = 25.6</p>"},{"location":"projects/amt/existing-tools/checklists/ai_assesment_tool_checklist/#security","title":"Security","text":"Requirement Priority Fulfilled Comments The tool must protect data and system from unauthorized access, use, disclosure, disruption, modification, or destruction. M 1 The data is stored in MongoDB Regular security audits and penetration testing are conducted. S 0 When running docker compose up, the docker client will tell there are quite some CVE vulnerabilities in there, an upgrade of the Node version would help much here The tool enforce authorization controls based on user roles and permissions, restricting access to sensitive data and functionalities. C 0.5 The tool has support for multiple users and roles (but we couldn't find a user management system) Data encryption is used for sensitive information at rest and in transit. C 1 When data is transferred to mongoDB, a secure connection is set-up and also in the DB it is encrypted by MongoDB, also you have an SSL connection with the tool The project allows for regular security audits and penetration testing to identify vulnerabilities and ensure system integrity. C 1 The tool does allow this, as it is open-source The tool implements backup functionality to ensure data availability in case of incidents. C 1 The data is store in a volume next to the main container of the <p>total_score = 7.5</p>"},{"location":"projects/amt/existing-tools/checklists/ai_assesment_tool_checklist/#compatibility","title":"Compatibility","text":"Requirement Priority Fulfilled Comments The tool is compatible with existing systems and infrastructure. M 1 As it is a container it can run on Kubernetes and therefore at Digilab The tool supports industry-standard data formats and protocols. M 1 Assessment and other config are stored in JSON The tool operates seamlessly on supported operating systems and hardware platforms. S 1 As it runs in a container it is able to run on all the major OSes if you have Docker Desktop or use a cloud version managed by yourself The tool supports commonly used data formats (e.g., CSV, Excel, JSON) for easy data exchange with other systems and tools. S 0 The tool currently only exports a pdf which is not an exchangeable format The tool integrates with existing security solutions. C 0 Not applicable as it is an UI <p>total_score = 11</p>"},{"location":"projects/amt/existing-tools/checklists/ai_assesment_tool_checklist/#accessibility","title":"Accessibility","text":"Requirement Priority Fulfilled Comments The tool is accessible to users with disabilities, following relevant accessibility standards (e.g., WCAG). S 0.1 The color scheme is pretty good viewable, but for the rest there are not accessibility features <p>total_score = 0.3</p>"},{"location":"projects/amt/existing-tools/checklists/ai_assesment_tool_checklist/#portability","title":"Portability","text":"Requirement Priority Fulfilled Comments The tool support a range of operating systems (e.g., Windows, macOS, Linux) commonly used within an organization. S 1 It is in docker so can run everywhere The tool minimizes dependencies on specific hardware or software configurations, promoting flexibility. S 1 This is all containerized The tool offers a cloud-based deployment option or be compatible with cloud environments for scalability and accessibility. S 1 As it is containerized we could host this ourselves in a cloud environment, the Belgium government does not offer a hosted version for you The tool adheres to relevant cloud security standards and best practices. S 0.8 The docker container does contain some outdated versions of for example Node. <p>total_score = 11.4</p>"},{"location":"projects/amt/existing-tools/checklists/ai_assesment_tool_checklist/#deployment","title":"Deployment","text":"Requirement Priority Fulfilled Comments The tool has an easy and user-friendly installation and configuration process. S 1 It was very easy to install out-of-the-box The tool has on-premise or cloud-based deployment options to cater to different organizational needs and infrastructure. S 0 The tool does not promise on-prem or cloud-based managed deployments <p>total_score = 3</p>"},{"location":"projects/amt/existing-tools/checklists/ai_assesment_tool_checklist/#legal-compliance","title":"Legal &amp; Compliance","text":"Requirement Priority Fulfilled Comments It is clear how the tool is funded to avoid improper influence due to conflicts of interest M 1 It is funded by the Belgian Government The tool is compliant with relevant legal and regulatory requirements. S 1 Yes EU license The tool adheres to (local) data privacy regulations like GDPR, ensuring the protection of user data. S 1 Data is stored locally The tool implements appropriate security measures to comply with industry regulations and standards. S 1 EUPL 1.2 license (although they say they have MIT license) The tool is licensed for use within the organization according to the terms and conditions of the license agreement. S 1 Yes, see above The tool respects intellectual property rights and avoid copyright infringement issues. S 1 Yes, see above <p>total_score = 19</p>"},{"location":"projects/amt/existing-tools/checklists/aiverify_checklist/","title":"AI Verify","text":""},{"location":"projects/amt/existing-tools/checklists/aiverify_checklist/#ai-verify","title":"AI Verify","text":"<p>See the introduction</p>"},{"location":"projects/amt/existing-tools/checklists/aiverify_checklist/#functionality","title":"Functionality","text":"Requirement Priority Fulfilled Comments The tool allows users to conduct technical tests on algorithms or models, including assessments of performance, bias, and fairness. To facilitate these tests, users can input relevant datasets, M 1 This is core functionality of AIVerify The tool allows users to choose which tests to perform. M 1 This is core functionality of AIVerify The tool allows users to fill out questionnaires to conduct impact assessments for AI. For example IAMA or ALTAI. M 1 This is core functionality of AIVerify, however work is needed to add extra impact assessments The tool can generate a human readable report. M 1 This is core functionality of AIVerify The tools works with a standardized report format, that it can read, write, and update. M 0 The outputted format is a PDF format, so this cannot be updated, or easily read by a machine. The tool supports plugin functionality so additional tests can be added easily. S 0.5 One can add a test as a plugin, it can however be a bit too technical still for many people. The tool allows to create custom reports based on components. S 1 One can slide the technical tests results and the assessment test results into a report which will be placed into a PDF It is possible to add custom components for reports. S 1 It is possible, but just like with tests can be hard for non-technical people The tool provides detailed logging, including tracking of different model versions, changes in impact assessments, and technical test results for individual runs. S 0.5 There are versions of models when uploaded, and the report itself is the technical test result of a run. Changes to impact assessments are not logged (only when a report is generated) The tool supports saving progress. S 1 Reports can be saved, while it is being constructed The tool can be used on an isolated system without an internet connection. S 1 Locally the docker container can be build and ran The tool offers options to discuss and document conversations. For example, to converse about technical tests or to collaborate on impact assessments. C 0 Only the end-result will be logged into the report The tool operates with complete data privacy; it does not share any data or logging information. C 1 The application is a docker application and does not do this The tool allows extension of report formats functionality. C 1 We could program this functionality in the tool and submit a PR The tool can be integrated in a CI/CD flow. C 0.5 It is possible, but would be very heavy to do so. The build time is quite large, and only the technical tests could be ran in an automated fashion The tool can be offered as a (cloud) service where no local installation is required. C 0 AIVerify is currently not doing this, we could however offer it as a cloud service It is possible to define and automate workflows for repetitive tasks. C 0 As this tool is focused on UI, this is not possible The tool offers pre-built connectors or low-code/no-code integration options to simplify the integration process. C 0 This is not included <p>total_score = 36</p>"},{"location":"projects/amt/existing-tools/checklists/aiverify_checklist/#reliability","title":"Reliability","text":"Requirement Priority Fulfilled Comments The tool operates consistently and reliably, meaning it delivers the same expected results every time you use it. M 1 The tool did not break down a single time while we were coding a plugin (only threw errors) The tool recovers automatically from common failures. S 1 Common failures like missing datasets or models are not breaking The tool recovers from failures quickly, minimizing data loss, for example by automatically saving intermediate test progress results. S 0.5 The assessments you need to manually save otherwise it will be lost, but over different sessions the data will be stored persistent even if the containers go down. Test results are only stored in the generated report The tool handles errors gracefully and informs users of any issues. S 1 When failed to generate a report the tool will log the error messages, otherwise when loading in data that is non existing the application (while not being very clear in error message) just continues with an error The tool provides clear error messages and instructions for troubleshooting. S 0.5 The test-engine-core is a dependency that is installed as a package, and therefore the error message will not contain error in that package <p>total_score = 13</p>"},{"location":"projects/amt/existing-tools/checklists/aiverify_checklist/#usability","title":"Usability","text":"Requirement Priority Fulfilled Comments The tool possess a clean, intuitive, and visually appealing UI that follows industry standards. S 1 The tool does follow the material design principles for example when you hover over items they will respond to user input The tool provides clear and consistent navigation, making it easy for users to find what they need. S 0.5 It is not completely clear where in the tool you are when interacting with it and sometimes you could go back to home but not always The tool is responsive and provides instant feedback. S 1 Even for jobs like generating tests and the report, it scheduled jobs and will notify you when it is done The user interface is multilingual and supports at least English. S 0.5 Currently it only supports english The tool offers keyboard shortcuts for efficient interaction. C 0 It is mainly UI and therefore no keyboard shortcuts The user interface can easily be translated into other languages. C 0.2 It would need quite some refactoring when adding support for the Dutch Language (especially the more technical words like Warning or the metadata on all the plugins <p>total_score = 9.4</p>"},{"location":"projects/amt/existing-tools/checklists/aiverify_checklist/#help-documentation","title":"Help &amp; Documentation","text":"Requirement Priority Fulfilled Comments The tool provides comprehensive online help documentation with searchable functionalities. S 0.8 From the end-user perspective yes, from the development perspective no (for example that you need to rebuild packages like the test-engine-core The tool offers context-sensitive help within the application. C 0 Not included in the tool The online documentation includes video tutorials and training materials for ease of learning. C 0 Although it contains many images The project provides readily available customer support through various channels  (e.g., email, phone, online chat) to address user inquiries and troubleshoot issues. C 0.2 Just email, which they do not respond to very quickly <p>total_score = 2.8</p>"},{"location":"projects/amt/existing-tools/checklists/aiverify_checklist/#performance-efficiency","title":"Performance Efficiency","text":"Requirement Priority Fulfilled Comments The tool operates efficiently and minimize resource utilization. M 0.5 The tool is efficient, minimal waiting and no lag although it uses up quite some resources which could be optimized The tool responds to user actions instantly. M 1 Instantaneous response time The tool is scalable to accommodate increased user base and data volume. S 0.5 As it is built into a container it can be made scalable with Kubernetes, but the the tool itself can become very slow when generating results for a large dataset and model (because of the extra overhead) <p>total_score = 7.5</p>"},{"location":"projects/amt/existing-tools/checklists/aiverify_checklist/#maintainability","title":"Maintainability","text":"Requirement Priority Fulfilled Comments The tool is easy to modify and maintain. M 0.2 Adding a new plugin for a model type was quite hard, other plugins however are more easier The tool adheres to industry coding standards and best practices to ensure code quality and maintainability. M 0.2 The docker side of the project could have a big improvement The code is written in a common, widely adopted and supported and actively used and maintained programming language. M 1 Backend in Python, Frontend in NextJs The project provides version control for code changes and rollback capabilities. M 0.8 The code is stored on Github, but the container itself not and also the packages which the tools depend on not The project is open source. M 1 Github link It is possible to contribute to the source. S 0.5 It is possible, although with our three features it takes a while for them to dedicated time for integration The system is modular, allowing for easy modification of individual components. S 0.5 The technical tests and assessments are easy to adjust, other core features not Diagnostic tools are available to identify and troubleshoot issues. S 0 Diagnosing some parts of the system took us quite some time as we couldn't properly debug in the containers <p>total_score = 15.8</p>"},{"location":"projects/amt/existing-tools/checklists/aiverify_checklist/#security","title":"Security","text":"Requirement Priority Fulfilled Comments The tool must protect data and system from unauthorized access, use, disclosure, disruption, modification, or destruction. M 0.5 This managed by that the data is stored in MongoDB however, it currently only has 1 user support Regular security audits and penetration testing are conducted. S 0.1 We are unaware of the security audits but they do have a security policy The tool enforce authorization controls based on user roles and permissions, restricting access to sensitive data and functionalities. C 0 Currently only 1 user can use the system and see all the data Data encryption is used for sensitive information at rest and in transit. C 1 When data is transferred to mongoDB, a secure connection is set-up and also in the DB it is encrypted by MongoDB, also you have an SSL connection with the tool The project allows for regular security audits and penetration testing to identify vulnerabilities and ensure system integrity. C 1 As you can install it locally, this is possible The tool implements backup functionality to ensure data availability in case of incidents. C 1 Data is stored persistent, so even if the tool breaks the data will be in volumes <p>total_score = 8.3</p>"},{"location":"projects/amt/existing-tools/checklists/aiverify_checklist/#compatibility","title":"Compatibility","text":"Requirement Priority Fulfilled Comments The tool is compatible with existing systems and infrastructure. M 1 As it is a container it can run on Kubernetes and therefore at Digilab The tool supports industry-standard data formats and protocols. M 1 Most Datasets and Models are supported by the tool The tool operates seamlessly on supported operating systems and hardware platforms. S 1 As it runs in a container it is able to run on all the major OS'es if you have Docker Desktop or use a cloud version managed by yourself The tool supports commonly used data formats (e.g., CSV, Excel, JSON) for easy data exchange with other systems and tools. S 0.5 As input many types are accepted, but only as export there is a PDF report The tool integrates with existing security solutions. C 0 It does not integrate with security solutions <p>total_score = 12.5</p>"},{"location":"projects/amt/existing-tools/checklists/aiverify_checklist/#accessibility","title":"Accessibility","text":"Requirement Priority Fulfilled Comments The tool is accessible to users with disabilities, following relevant accessibility standards (e.g., WCAG). S 0 It is not clear what the tool actually does with one look, also the color change when hovering over elements is not a large difference compared to the original color (the purple and pink) <p>total_score = 0</p>"},{"location":"projects/amt/existing-tools/checklists/aiverify_checklist/#portability","title":"Portability","text":"Requirement Priority Fulfilled Comments The tool support a range of operating systems (e.g., Windows, macOS, Linux) commonly used within an organization. S 1 It is containerized The tool minimizes dependencies on specific hardware or software configurations, promoting flexibility. S 1 This is all containerized The tool offers a cloud-based deployment option or be compatible with cloud environments for scalability and accessibility. S 1 As it is containerized we could host this ourselves in a cloud environment The tool adheres to relevant cloud security standards and best practices. S 0.5 The making of the container it self is lacking some best practices, otherwise the cloud security standards are not applicable as it is a self-hosted tool <p>total_score = 10.5</p>"},{"location":"projects/amt/existing-tools/checklists/aiverify_checklist/#deployment","title":"Deployment","text":"Requirement Priority Fulfilled Comments The tool has an easy and user-friendly installation and configuration process. S 0.5 You need to be technical to be able to install and deploy, but then it is relatively easy The tool has on-premise or cloud-based deployment options to cater to different organizational needs and infrastructure. S 0 The tool does not promise on-prem or cloud-based managed deployments <p>total_score = 1.5</p>"},{"location":"projects/amt/existing-tools/checklists/aiverify_checklist/#legal-compliance","title":"Legal &amp; Compliance","text":"Requirement Priority Fulfilled Comments It is clear how the tool is funded to avoid improper influence due to conflicts of interest M 1 On the website it is stated, that many commercial partners fund this project The tool is compliant with relevant legal and regulatory requirements. S 1 The tool adheres to (local) data privacy regulations like GDPR, ensuring the protection of user data. S 1 The tool implements appropriate security measures to comply with industry regulations and standards. S 1 The tool is licensed for use within the organization according to the terms and conditions of the license agreement. S 1 Apache 2.0 license The tool respects intellectual property rights and avoid copyright infringement issues. S 1 <p>total_score = 19</p>"},{"location":"projects/amt/existing-tools/checklists/holisticai_checklist/","title":"Holistic AI","text":""},{"location":"projects/amt/existing-tools/checklists/holisticai_checklist/#holistic-ai","title":"Holistic AI","text":"<p>See the introduction. It is a toolkit just like IBM-360-Toolkit for a data scientist to research bias and also to mitigate it immediately.</p>"},{"location":"projects/amt/existing-tools/checklists/holisticai_checklist/#functionality","title":"Functionality","text":"Requirement Priority Fulfilled Comments The tool allows users to conduct technical tests on algorithms or models, including assessments of performance, bias, and fairness. To facilitate these tests, users can input relevant datasets, M 1 The tests which can be executed are written in the Holistic AI documentation The tool allows users to choose which tests to perform. M 1 In code the user is free to choose any test The tool allows users to fill out questionnaires to conduct impact assessments for AI. For example IAMA or ALTAI. M 0 The tool only does technical tests The tool can generate a human readable report. M 0 The toolkit itself cannot make a human readable report, it only generates results which then needs to be interpreted The tools works with a standardized report format, that it can read, write, and update. M 0 The only format it outputs are specific numbers, so no standardized format or even een report format The tool supports plugin functionality so additional tests can be added easily. S 0 All the bias tests are put in a single script which making additional tests a bit cumbersome and leas developer-friendly The tool allows to create custom reports based on components. S 0 Does not allow reports export It is possible to add custom components for reports. S 0 Does not allow reports export The tool provides detailed logging, including tracking of different model versions, changes in impact assessments, and technical test results for individual runs. S 0 Not ouf of the box, but this could be written in code by the owner of the algorithm The tool supports saving progress. S 0 Not ouf of the box, but this could be written in code by the owner of the algorithm The tool can be used on an isolated system without an internet connection. S 1 As a python tool this is possible The tool offers options to discuss and document conversations. For example, to converse about technical tests or to collaborate on impact assessments. C 0 This is not supported The tool operates with complete data privacy; it does not share any data or logging information. C 1 The local tool does not share anything to the outside world The tool allows extension of report formats functionality. C 0 This is not what the tool is built for The tool can be integrated in a CI/CD flow. C 1 As it is a python package it can be included in a CI pipeline The tool can be offered as a (cloud) service where no local installation is required. C 0 Not immediately, an UI needs to be build around it It is possible to define and automate workflows for repetitive tasks. C 1 Automated tests could be programmed specifically from this tool The tool offers pre-built connectors or low-code/no-code integration options to simplify the integration process. C 0 Not supported by the tool <p>total_score = 17</p>"},{"location":"projects/amt/existing-tools/checklists/holisticai_checklist/#reliability","title":"Reliability","text":"Requirement Priority Fulfilled Comments The tool operates consistently and reliably, meaning it delivers the same expected results every time you use it. M 1 The tool recovers automatically from common failures. S 1 The tool recovers from failures quickly, minimizing data loss, for example by automatically saving intermediate test progress results. S 1 The tool handles errors gracefully and informs users of any issues. S 1 The tool provides clear error messages and instructions for troubleshooting. S 1 <p>total_score = 16</p>"},{"location":"projects/amt/existing-tools/checklists/holisticai_checklist/#usability","title":"Usability","text":"Requirement Priority Fulfilled Comments The tool possess a clean, intuitive, and visually appealing UI that follows industry standards. S 0 There is no user-interface The tool provides clear and consistent navigation, making it easy for users to find what they need. S 0 There is no user-interface The tool is responsive and provides instant feedback. S 0 There is no user-interface The user interface is multilingual and supports at least English. S 0 There is no user-interface The tool offers keyboard shortcuts for efficient interaction. C 0 There is no user-interface The user interface can easily be translated into other languages. C 0 There is no user-interface <p>total_score = 0</p>"},{"location":"projects/amt/existing-tools/checklists/holisticai_checklist/#help-documentation","title":"Help &amp; Documentation","text":"Requirement Priority Fulfilled Comments The tool provides comprehensive online help documentation with searchable functionalities. S 0.2 There is some documentation but it is not very helpful The tool offers context-sensitive help within the application. C 0 As a Python tool, no The online documentation includes video tutorials and training materials for ease of learning. C 0 Ths is not there The project provides readily available customer support through various channels  (e.g., email, phone, online chat) to address user inquiries and troubleshoot issues. C 0.5 You can contact sales through their website and respond on Github, Github seems to be an okay response time (but not a large community) <p>total_score = 1.6</p>"},{"location":"projects/amt/existing-tools/checklists/holisticai_checklist/#performance-efficiency","title":"Performance Efficiency","text":"Requirement Priority Fulfilled Comments The tool operates efficiently and minimize resource utilization. M 1 very lightweight as a python package The tool responds to user actions instantly. M 1 It will return output instantly The tool is scalable to accommodate increased user base and data volume. S 1 This would be installed distributed and therefore would be scalable, with large datasets it is still very quick <p>total_score = 11</p>"},{"location":"projects/amt/existing-tools/checklists/holisticai_checklist/#maintainability","title":"Maintainability","text":"Requirement Priority Fulfilled Comments The tool is easy to modify and maintain. M 0.5 It is less modular because most of the tests are written in a single script The tool adheres to industry coding standards and best practices to ensure code quality and maintainability. M 0.5 They use pre-commit hooks, but the codebase seems to be a bit weirdly structured The code is written in a common, widely adopted and supported and actively used and maintained programming language. M 1 It is written in Python The project provides version control for code changes and rollback capabilities. M 1 It is hosted on Github The project is open source. M 1 Hosted on GitHub It is possible to contribute to the source. S 1 It is possible and they respond to contributions The system is modular, allowing for easy modification of individual components. S 0.5 See the first point Diagnostic tools are available to identify and troubleshoot issues. S 1 Just standard python troubleshooting tools <p>total_score = 23.5</p>"},{"location":"projects/amt/existing-tools/checklists/holisticai_checklist/#security","title":"Security","text":"Requirement Priority Fulfilled Comments The tool must protect data and system from unauthorized access, use, disclosure, disruption, modification, or destruction. M 0 Not applicable Regular security audits and penetration testing are conducted. S 0 It is not stated on the repository that they do something with security The tool enforce authorization controls based on user roles and permissions, restricting access to sensitive data and functionalities. C 0 The tool does not have Users or Access control Data encryption is used for sensitive information at rest and in transit. C 0 Transitionary data is not stored The project allows for regular security audits and penetration testing to identify vulnerabilities and ensure system integrity. C 1 This is not blocked by the tool The tool implements backup functionality to ensure data availability in case of incidents. C 0 Not supported <p>total_score = 2</p>"},{"location":"projects/amt/existing-tools/checklists/holisticai_checklist/#compatibility","title":"Compatibility","text":"Requirement Priority Fulfilled Comments The tool is compatible with existing systems and infrastructure. M 1 It can be imported in Python The tool supports industry-standard data formats and protocols. M 0 it does not standardize at all in the output of the tests The tool operates seamlessly on supported operating systems and hardware platforms. S 1 Python can be ran on any system The tool supports commonly used data formats (e.g., CSV, Excel, JSON) for easy data exchange with other systems and tools. S 1 If it can be imported in Python/R it is supported The tool integrates with existing security solutions. C 0 Not applicable <p>total_score = 10</p>"},{"location":"projects/amt/existing-tools/checklists/holisticai_checklist/#accessibility","title":"Accessibility","text":"Requirement Priority Fulfilled Comments The tool is accessible to users with disabilities, following relevant accessibility standards (e.g., WCAG). S 0 You need to be a programmer to use it, and that is not your typical user with disabilities <p>total_score = 0</p>"},{"location":"projects/amt/existing-tools/checklists/holisticai_checklist/#portability","title":"Portability","text":"Requirement Priority Fulfilled Comments The tool support a range of operating systems (e.g., Windows, macOS, Linux) commonly used within an organization. S 0.5 As it is a python tool it is supported anywhere python runs The tool minimizes dependencies on specific hardware or software configurations, promoting flexibility. S 1 It is a python tool The tool offers a cloud-based deployment option or be compatible with cloud environments for scalability and accessibility. S 1 The company behind Holistic AI offers a whole range of services included an UI which uses this open-source toolkit The tool adheres to relevant cloud security standards and best practices. S 0 On their website they do not speak about where the data of their solution will go, this is not very transparent <p>total_score = 7.5</p>"},{"location":"projects/amt/existing-tools/checklists/holisticai_checklist/#deployment","title":"Deployment","text":"Requirement Priority Fulfilled Comments The tool has an easy and user-friendly installation and configuration process. S 0.2 You need to have some developer knowledge and also knowledge about the technical tests to use The tool has on-premise or cloud-based deployment options to cater to different organizational needs and infrastructure. S 1 Yes the tool can be used as a cloud-based deployment but then with a whole UI around it <p>total_score = 3.6</p>"},{"location":"projects/amt/existing-tools/checklists/holisticai_checklist/#legal-compliance","title":"Legal &amp; Compliance","text":"Requirement Priority Fulfilled Comments It is clear how the tool is funded to avoid improper influence due to conflicts of interest M 1 The tool is owned by a private company but has been made open source to the public The tool is compliant with relevant legal and regulatory requirements. S 1 Under the apache 2.0 license The tool adheres to (local) data privacy regulations like GDPR, ensuring the protection of user data. S 1 Data stays locally The tool implements appropriate security measures to comply with industry regulations and standards. S 0 The repo does not speak about security at all The tool is licensed for use within the organization according to the terms and conditions of the license agreement. S 1 Under the apache 2.0 license The tool respects intellectual property rights and avoid copyright infringement issues. S 1 <p>total_score = 16</p>"},{"location":"projects/amt/existing-tools/checklists/ibm_360_research_toolkit_checklist/","title":"IBM Research 360 Toolkit","text":""},{"location":"projects/amt/existing-tools/checklists/ibm_360_research_toolkit_checklist/#ibm-research-360-toolkit","title":"IBM Research 360 Toolkit","text":"<p>See the introduction, same thing as verifyML this has no frontend baked in, but has some nice integrations with MLops tooling like Kubeflow Pipelines. The IBM Research 360 toolkit is actually a collection of three open-source toolkits as stated by their Github repo; AI Fairness 360, AI Explainability 360, Adversarial Robustness 360. The strong suite of this toolkit that it considers bias in the whole lifecycle of the model; (dataset, training, output).</p>"},{"location":"projects/amt/existing-tools/checklists/ibm_360_research_toolkit_checklist/#functionality","title":"Functionality","text":"Requirement Priority Fulfilled Comments The tool allows users to conduct technical tests on algorithms or models, including assessments of performance, bias, and fairness. To facilitate these tests, users can input relevant datasets, M 1 Fairness, Explainability and security can be tested with the suite of tools The tool allows users to choose which tests to perform. M 1 The websites of contain a whole explanation of which tests to perform AIF Website, AIX website, ART website The tool allows users to fill out questionnaires to conduct impact assessments for AI. For example IAMA or ALTAI. M 0 The tool only does technical tests The tool can generate a human readable report. M 0 The toolkit itself cannot make a human readable report, it only generates results which then needs to be interpreted The tools works with a standardized report format, that it can read, write, and update. M 0 The only format it outputs are specific numbers, so no standardized format or even een report format The tool supports plugin functionality so additional tests can be added easily. S 1 Only the repository new tests could be added quite easily if you understand Python The tool allows to create custom reports based on components. S 0 The tool does not generate reports It is possible to add custom components for reports. S 0 The tool does not generate reports The tool provides detailed logging, including tracking of different model versions, changes in impact assessments, and technical test results for individual runs. S 0 Not ouf of the box, but this could be written in code by the owner of the algorithm The tool supports saving progress. S 0 Not ouf of the box, but this could be written in code by the owner of the algorithm The tool can be used on an isolated system without an internet connection. S 1 As it can be imported as a python or r library The tool offers options to discuss and document conversations. For example, to converse about technical tests or to collaborate on impact assessments. C 0 This is not supported, there is no UI The tool operates with complete data privacy; it does not share any data or logging information. C 1 The tool does not share data The tool allows extension of report formats functionality. C 0 The tool does not generate reports The tool can be integrated in a CI/CD flow. C 1 As it is a programming toolkit it can be used in a CI/CD pipeline The tool can be offered as a (cloud) service where no local installation is required. C 0 not immediately, then an UI needs to be made It is possible to define and automate workflows for repetitive tasks. C 1 We could automate specific tests which we deem necessary or standard The tool offers pre-built connectors or low-code/no-code integration options to simplify the integration process. C 0 Purely written in Python <p>total_score = 20</p>"},{"location":"projects/amt/existing-tools/checklists/ibm_360_research_toolkit_checklist/#reliability","title":"Reliability","text":"Requirement Priority Fulfilled Comments The tool operates consistently and reliably, meaning it delivers the same expected results every time you use it. M 1 The tool recovers automatically from common failures. S 1 The tool recovers from failures quickly, minimizing data loss, for example by automatically saving intermediate test progress results. S 1 The tool handles errors gracefully and informs users of any issues. S 1 The tool provides clear error messages and instructions for troubleshooting. S 1 <p>total_score = 16</p>"},{"location":"projects/amt/existing-tools/checklists/ibm_360_research_toolkit_checklist/#usability","title":"Usability","text":"Requirement Priority Fulfilled Comments The tool possess a clean, intuitive, and visually appealing UI that follows industry standards. S 0 There is no user-interface The tool provides clear and consistent navigation, making it easy for users to find what they need. S 0 There is no user-interface The tool is responsive and provides instant feedback. S 0 There is no user-interface The user interface is multilingual and supports at least English. S 0 There is no user-interface The tool offers keyboard shortcuts for efficient interaction. C 0 There is no user-interface The user interface can easily be translated into other languages. C 0 There is no user-interface <p>total_score = 0</p>"},{"location":"projects/amt/existing-tools/checklists/ibm_360_research_toolkit_checklist/#help-documentation","title":"Help &amp; Documentation","text":"Requirement Priority Fulfilled Comments The tool provides comprehensive online help documentation with searchable functionalities. S 0.8 On the website of the specific toolkit you can find many docs but you cannot search The tool offers context-sensitive help within the application. C 0 Within the application (as it is not an UI, does not offer specific help) The online documentation includes video tutorials and training materials for ease of learning. C 1 The amount of tutorials is extensive even videos of its usage The project provides readily available customer support through various channels  (e.g., email, phone, online chat) to address user inquiries and troubleshoot issues. C 1 You can ask questions at the repository, but also in slack and many people are using this <p>total_score = 6.4</p>"},{"location":"projects/amt/existing-tools/checklists/ibm_360_research_toolkit_checklist/#performance-efficiency","title":"Performance Efficiency","text":"Requirement Priority Fulfilled Comments The tool operates efficiently and minimize resource utilization. M 1 very lightweight as a python package The tool responds to user actions instantly. M 1 It will return output instantly The tool is scalable to accommodate increased user base and data volume. S 1 This would be installed distributed and therefore would be scalable, with large datasets it is still very quick <p>total_score = 11</p>"},{"location":"projects/amt/existing-tools/checklists/ibm_360_research_toolkit_checklist/#maintainability","title":"Maintainability","text":"Requirement Priority Fulfilled Comments The tool is easy to modify and maintain. M 1 The repositories are very well structured and therefore easy to adjust The tool adheres to industry coding standards and best practices to ensure code quality and maintainability. M 1 Although it doesn't have pre-commit hooks it does have a CONTRIBUTING.rst where the rules of good practices are written down The code is written in a common, widely adopted and supported and actively used and maintained programming language. M 1 It is written in Python The project provides version control for code changes and rollback capabilities. M 1 The code is hosted on Github The project is open source. M 1 At the beginning of this doc you can find the links to the repositories It is possible to contribute to the source. S 1 They have merged many outside requests, so this is fine The system is modular, allowing for easy modification of individual components. S 1 Tests can very easily be added if you understand Python Diagnostic tools are available to identify and troubleshoot issues. S 1 Just standard python troubleshooting tools <p>total_score = 29</p>"},{"location":"projects/amt/existing-tools/checklists/ibm_360_research_toolkit_checklist/#security","title":"Security","text":"Requirement Priority Fulfilled Comments The tool must protect data and system from unauthorized access, use, disclosure, disruption, modification, or destruction. M 0 not applicable Regular security audits and penetration testing are conducted. S 0 It is not stated on the repository that they do something with security The tool enforce authorization controls based on user roles and permissions, restricting access to sensitive data and functionalities. C 0 The tool does not have Users or Access control Data encryption is used for sensitive information at rest and in transit. C 0 Transitionary data is not stored The project allows for regular security audits and penetration testing to identify vulnerabilities and ensure system integrity. C 1 This is not blocked by the tool The tool implements backup functionality to ensure data availability in case of incidents. C 0 Not supported <p>total_score = 2</p>"},{"location":"projects/amt/existing-tools/checklists/ibm_360_research_toolkit_checklist/#compatibility","title":"Compatibility","text":"Requirement Priority Fulfilled Comments The tool is compatible with existing systems and infrastructure. M 1 It can easily be imported in Python or R The tool supports industry-standard data formats and protocols. M 0.5 It does not standardize really on any output from the tests The tool operates seamlessly on supported operating systems and hardware platforms. S 1 As a python and R tool it can be run on systems where these can be ran The tool supports commonly used data formats (e.g., CSV, Excel, JSON) for easy data exchange with other systems and tools. S 1 These can be used if they are imported in python and R The tool integrates with existing security solutions. C 1 The Adversarial Robustness Toolbox can be used to test for the security of AI Systems <p>total_score = 14</p>"},{"location":"projects/amt/existing-tools/checklists/ibm_360_research_toolkit_checklist/#accessibility","title":"Accessibility","text":"Requirement Priority Fulfilled Comments The tool is accessible to users with disabilities, following relevant accessibility standards (e.g., WCAG). S 0 You need to be a programmer to use it, and that is not your typical user with disabilities <p>total_score = 0</p>"},{"location":"projects/amt/existing-tools/checklists/ibm_360_research_toolkit_checklist/#portability","title":"Portability","text":"Requirement Priority Fulfilled Comments The tool support a range of operating systems (e.g., Windows, macOS, Linux) commonly used within an organization. S 0.7 If you can run python, which is not always possible within the government for example, but R could be more easy to be run on places The tool minimizes dependencies on specific hardware or software configurations, promoting flexibility. S 1 Just a python tool, no UI which is fairly minimal The tool offers a cloud-based deployment option or be compatible with cloud environments for scalability and accessibility. S 0 It is not offered as a cloud-based option The tool adheres to relevant cloud security standards and best practices. S 0 Not relevant <p>total_score = 5.1</p>"},{"location":"projects/amt/existing-tools/checklists/ibm_360_research_toolkit_checklist/#deployment","title":"Deployment","text":"Requirement Priority Fulfilled Comments The tool has an easy and user-friendly installation and configuration process. S 0.4 You need to have some developer knowledge and also knowledge about the technical tests to use. But then it is quite easy and works fairly quickly The tool has on-premise or cloud-based deployment options to cater to different organizational needs and infrastructure. S 0 Not applicable <p>total_score = 1.2</p>"},{"location":"projects/amt/existing-tools/checklists/ibm_360_research_toolkit_checklist/#legal-compliance","title":"Legal &amp; Compliance","text":"Requirement Priority Fulfilled Comments It is clear how the tool is funded to avoid improper influence due to conflicts of interest M 1 The tool was from IBM, but slowly they are removing the IBM branding from this and the tool is now owned by the LF AI Foundation (where big companies are part of) The tool is compliant with relevant legal and regulatory requirements. S 1 All three tools have apache 2.0 license The tool adheres to (local) data privacy regulations like GDPR, ensuring the protection of user data. S 1 Data will stay local The tool implements appropriate security measures to comply with industry regulations and standards. S 0 Nothing is known about the security measures of the toolkits The tool is licensed for use within the organization according to the terms and conditions of the license agreement. S 1 All three tools have apache 2.0 license The tool respects intellectual property rights and avoid copyright infringement issues. S 1 The specific tests are implementations of papers which are open for everyone <p>total_score = 16</p>"},{"location":"projects/amt/existing-tools/checklists/verifyml_checklist/","title":"VerifyML","text":""},{"location":"projects/amt/existing-tools/checklists/verifyml_checklist/#verifyml","title":"VerifyML","text":"<p>See the introduction, the maker also suggests to use an front-end tool to collaboratively change the model card. Model Card Editor this is not open-source and also the developer suggests in this issue to not use this tool but to use tools like AIVerify. This checklist only looks at the verifyML python toolkit and not the web interface.</p>"},{"location":"projects/amt/existing-tools/checklists/verifyml_checklist/#functionality","title":"Functionality","text":"Requirement Priority Fulfilled Comments The tool allows users to conduct technical tests on algorithms or models, including assessments of performance, bias, and fairness. To facilitate these tests, users can input relevant datasets, M 1 The tool does allow a few standardized tests, specified in the VerifyML model tests README The tool allows users to choose which tests to perform. M 1 In code the user is free to choose any test The tool allows users to fill out questionnaires to conduct impact assessments for AI. For example IAMA or ALTAI. M 0 The tool can generate a human readable report. M 1 The tool can visualize model cards that are generated by it The tools works with a standardized report format, that it can read, write, and update. M 1 It generates html which can be imported by a machine The tool supports plugin functionality so additional tests can be added easily. S 1 Any test can be ran by the user itself and the output imported in the model card generated by the tool The tool allows to create custom reports based on components. S 0 It doesn't offer any standardization in what to put in the report It is possible to add custom components for reports. S 1 Anything can be put in the model card, which makes it very flexible The tool provides detailed logging, including tracking of different model versions, changes in impact assessments, and technical test results for individual runs. S 0 Not ouf of the box, but this could be written in code by the owner of the algorithm The tool supports saving progress. S 1 Once the modelcard is generated it could be loaded in again and be changed The tool can be used on an isolated system without an internet connection. S 1 Once the tool is imported in python it can be used without an internet connection The tool offers options to discuss and document conversations. For example, to converse about technical tests or to collaborate on impact assessments. C 0 Assessments are not supported The tool operates with complete data privacy; it does not share any data or logging information. C 1 It does not do this The tool allows extension of report formats functionality. C 1 As it exports html, it can also be transferred to json or markdown The tool can be integrated in a CI/CD flow. C 1 The automated tests could be ran in the CI/CD tool to generated a model card The tool can be offered as a (cloud) service where no local installation is required. C 0 The python tool itself not, but a frontend which needs to be developed yes It is possible to define and automate workflows for repetitive tasks. C 1 As it is written in python this can be automated easily The tool offers pre-built connectors or low-code/no-code integration options to simplify the integration process. C 0 The tool does this not <p>total_score = 42</p>"},{"location":"projects/amt/existing-tools/checklists/verifyml_checklist/#reliability","title":"Reliability","text":"Requirement Priority Fulfilled Comments The tool operates consistently and reliably, meaning it delivers the same expected results every time you use it. M 1 Once you have located the right (older) libraries it runs pretty smoothly and reliably The tool recovers automatically from common failures. S 0 Library dependencies needs to be solved by yourself as this is not handled by the tool (especially graphs) The tool recovers from failures quickly, minimizing data loss, for example by automatically saving intermediate test progress results. S 0 It does not store any intermediary results The tool handles errors gracefully and informs users of any issues. S 0 It just breaks, you need to explicitly export the model card for it to saved The tool provides clear error messages and instructions for troubleshooting. S 0 The error messages are python error messages unrelated to the tool <p>total_score = 4</p>"},{"location":"projects/amt/existing-tools/checklists/verifyml_checklist/#usability","title":"Usability","text":"Requirement Priority Fulfilled Comments The tool possess a clean, intuitive, and visually appealing UI that follows industry standards. S 0 There is no user interface The tool provides clear and consistent navigation, making it easy for users to find what they need. S 0 There is no user interface The tool is responsive and provides instant feedback. S 0 There is no user interface The user interface is multilingual and supports at least English. S 0 There is no user interface The tool offers keyboard shortcuts for efficient interaction. C 0 There is no user interface The user interface can easily be translated into other languages. C 0 There is no user interface <p>total_score = 0</p>"},{"location":"projects/amt/existing-tools/checklists/verifyml_checklist/#help-documentation","title":"Help &amp; Documentation","text":"Requirement Priority Fulfilled Comments The tool provides comprehensive online help documentation with searchable functionalities. S 0.5 The documentation is quite concise and helpful, but it is outdated The tool offers context-sensitive help within the application. C 0 No context info whatsoever The online documentation includes video tutorials and training materials for ease of learning. C 0 Just documentation The project provides readily available customer support through various channels  (e.g., email, phone, online chat) to address user inquiries and troubleshoot issues. C 0 The people who worked on the tool are quick to respond to issues, but they don't support the tool anymore <p>total_score = 1.5</p>"},{"location":"projects/amt/existing-tools/checklists/verifyml_checklist/#performance-efficiency","title":"Performance Efficiency","text":"Requirement Priority Fulfilled Comments The tool operates efficiently and minimize resource utilization. M 1 Very lightweight tool, as it is a python package The tool responds to user actions instantly. M 1 When run, it returns instantly The tool is scalable to accommodate increased user base and data volume. S 1 This would be installed distributed and therefore would be scalable, with large datasets it is still very quick <p>total_score = 11</p>"},{"location":"projects/amt/existing-tools/checklists/verifyml_checklist/#maintainability","title":"Maintainability","text":"Requirement Priority Fulfilled Comments The tool is easy to modify and maintain. M 1 The tool itself it not so large and written with tools we are all quite aware of The tool adheres to industry coding standards and best practices to ensure code quality and maintainability. M 1 The repository has poetry, pre-commit hooks, has a CI, and looks well structured The code is written in a common, widely adopted and supported and actively used and maintained programming language. M 1 in Python and jupyter notebooks The project provides version control for code changes and rollback capabilities. M 1 It is hosted on Github The project is open source. M 1 Apache 2.0 license It is possible to contribute to the source. S 0 The project is not active supported anymore, so we would need to make a fork and make that the main source The system is modular, allowing for easy modification of individual components. S 0.5 The idea of a model card is pretty modular, and can be changed any way we like. Adding assessments in the tool would be quite the effort Diagnostic tools are available to identify and troubleshoot issues. S 1 Just standard python troubleshooting tools <p>total_score = 24.5</p>"},{"location":"projects/amt/existing-tools/checklists/verifyml_checklist/#security","title":"Security","text":"Requirement Priority Fulfilled Comments The tool must protect data and system from unauthorized access, use, disclosure, disruption, modification, or destruction. M 0 not applicable Regular security audits and penetration testing are conducted. S 0 As the tool is not actively maintained anymore The tool enforce authorization controls based on user roles and permissions, restricting access to sensitive data and functionalities. C 0 As this is a local import only, this is managed by the developer Data encryption is used for sensitive information at rest and in transit. C 0 Intermediary data is not stored, and the end result is put in html with no encryption The project allows for regular security audits and penetration testing to identify vulnerabilities and ensure system integrity. C 1 It does not block this for users to do this The tool implements backup functionality to ensure data availability in case of incidents. C 0 Not supported <p>total_score = 2</p>"},{"location":"projects/amt/existing-tools/checklists/verifyml_checklist/#compatibility","title":"Compatibility","text":"Requirement Priority Fulfilled Comments The tool is compatible with existing systems and infrastructure. M 1 It can be easily imported and installed in python The tool supports industry-standard data formats and protocols. M 1 Standardized tests are used and the output format is html The tool operates seamlessly on supported operating systems and hardware platforms. S 1 As it is a python tool, anywhere where python can run this can also be run The tool supports commonly used data formats (e.g., CSV, Excel, JSON) for easy data exchange with other systems and tools. S 1 This can be imported The tool integrates with existing security solutions. C 0 It does not do such a thing <p>total_score = 14</p>"},{"location":"projects/amt/existing-tools/checklists/verifyml_checklist/#accessibility","title":"Accessibility","text":"Requirement Priority Fulfilled Comments The tool is accessible to users with disabilities, following relevant accessibility standards (e.g., WCAG). S 0 You need to be a programmer to use it, and that is not your typical user with disabilities <p>total_score = 0</p>"},{"location":"projects/amt/existing-tools/checklists/verifyml_checklist/#portability","title":"Portability","text":"Requirement Priority Fulfilled Comments The tool support a range of operating systems (e.g., Windows, macOS, Linux) commonly used within an organization. S 0.5 If you can run python, which is not always possible within the government for example The tool minimizes dependencies on specific hardware or software configurations, promoting flexibility. S 1 As it is a python tool The tool offers a cloud-based deployment option or be compatible with cloud environments for scalability and accessibility. S 0 It is not offered as a cloud-based option The tool adheres to relevant cloud security standards and best practices. S 0 On the github nothing is mentioned about security and for the cloud version it is not applicable <p>total_score = 4.5</p>"},{"location":"projects/amt/existing-tools/checklists/verifyml_checklist/#deployment","title":"Deployment","text":"Requirement Priority Fulfilled Comments The tool has an easy and user-friendly installation and configuration process. S 0.2 You need to have some developer knowledge and also knowledge about the technical tests to use The tool has on-premise or cloud-based deployment options to cater to different organizational needs and infrastructure. S 0 Not applicable <p>total_score = 0.6</p>"},{"location":"projects/amt/existing-tools/checklists/verifyml_checklist/#legal-compliance","title":"Legal &amp; Compliance","text":"Requirement Priority Fulfilled Comments It is clear how the tool is funded to avoid improper influence due to conflicts of interest M 1 It was developed during a competition and it does not receive funding anymore The tool is compliant with relevant legal and regulatory requirements. S 1 Under the apache 2.0 license The tool adheres to (local) data privacy regulations like GDPR, ensuring the protection of user data. S 1 Data will stay local The tool implements appropriate security measures to comply with industry regulations and standards. S 0 The repo does not speak about security at all The tool is licensed for use within the organization according to the terms and conditions of the license agreement. S 1 Under the apache 2.0 license The tool respects intellectual property rights and avoid copyright infringement issues. S 1 <p>total_score = 16</p>"},{"location":"projects/amt/existing-tools/comparison/requirements/","title":"Requirements for tools for Transparency of Algorithmic Decision making","text":""},{"location":"projects/amt/existing-tools/comparison/requirements/#requirements-for-tools-for-transparency-of-algorithmic-decision-making","title":"Requirements for tools for Transparency of Algorithmic Decision making","text":"<p>This document contains a checklist with requirements for tools we could use to help with the transparency of algorithmic decision making.</p> <p>The requirements are based on:</p> <ul> <li>ISO 25010 standard: This standard defines the eight quality characteristics and provides a framework for evaluating software quality.</li> <li>Industry best practices: This includes a broad range of recommendations and guidelines for IT tool development and implementation.</li> <li>Common IT tool requirements: This information was gathered by analyzing various sources, such as documentation from popular IT tools, user reviews, and articles from reputable tech publications that discuss essential features and functionalities expected from different types of IT tools.</li> <li>Internal discussion and common sense: While above sources are already exhaustive, we also used team discussions and our own knowledge.</li> </ul>"},{"location":"projects/amt/existing-tools/comparison/requirements/#overview-of-requirements","title":"Overview of requirements","text":"<p>The requirements have been given a priority based on the MoSCoW scale to allow for tool comparison.</p>"},{"location":"projects/amt/existing-tools/comparison/requirements/#functionality","title":"Functionality","text":"Requirement Priority The tool allows users to conduct technical tests on algorithms or models, including assessments of performance, bias, and fairness. To facilitate these tests, users can input relevant datasets, M The tool allows users to choose which tests to perform. M The tool allows users to fill out questionnaires to conduct impact assessments for AI. For example IAMA or ALTAI. M The tool can generate a human readable report. M The tools works with a standardized report format, that it can read, write, and update. M The tool supports plugin functionality so additional tests can be added easily. S The tool allows to create custom reports based on components. S It is possible to add custom components for reports. S The tool provides detailed logging, including tracking of different model versions, changes in impact assessments, and technical test results for individual runs. S The tool supports saving progress. S The tool can be used on an isolated system without an internet connection. S The tool offers options to discuss and document conversations. For example, to converse about technical tests or to collaborate on impact assessments. C The tool operates with complete data privacy; it does not share any data or logging information. C The tool allows extension of report formats functionality. C The tool can be integrated in a CI/CD flow. C The tool can be offered as a (cloud) service where no local installation is required. C It is possible to define and automate workflows for repetitive tasks. C The tool offers pre-built connectors or low-code/no-code integration options to simplify the integration process. C"},{"location":"projects/amt/existing-tools/comparison/requirements/#reliability","title":"Reliability","text":"Requirement Priority The tool operates consistently and reliably, meaning it delivers the same expected results every time you use it. M The tool recovers automatically from common failures. S The tool recovers from failures quickly, minimizing data loss, for example by automatically saving intermediate test progress results. S The tool handles errors gracefully and informs users of any issues. S The tool provides clear error messages and instructions for troubleshooting. S"},{"location":"projects/amt/existing-tools/comparison/requirements/#usability","title":"Usability","text":"Requirement Priority The tool possess a clean, intuitive, and visually appealing UI that follows industry standards. S The tool provides clear and consistent navigation, making it easy for users to find what they need. S The tool is responsive and provides instant feedback. S The user interface is multilingual and supports at least English. S The tool offers keyboard shortcuts for efficient interaction. C The user interface can easily be translated into other languages. C"},{"location":"projects/amt/existing-tools/comparison/requirements/#help-documentation","title":"Help &amp; Documentation","text":"Requirement Priority The tool provides comprehensive online help documentation with searchable functionalities. S The tool offers context-sensitive help within the application. C The online documentation includes video tutorials and training materials for ease of learning. C The project provides readily available customer support through various channels  (e.g., email, phone, online chat) to address user inquiries and troubleshoot issues. C"},{"location":"projects/amt/existing-tools/comparison/requirements/#performance-efficiency","title":"Performance Efficiency","text":"Requirement Priority The tool operates efficiently and minimize resource utilization. M The tool responds to user actions instantly. M The tool is scalable to accommodate increased user base and data volume. S"},{"location":"projects/amt/existing-tools/comparison/requirements/#maintainability","title":"Maintainability","text":"Requirement Priority The tool is easy to modify and maintain. M The tool adheres to industry coding standards and best practices to ensure code quality and maintainability. M The code is written in a common, widely adopted and supported and actively used and maintained programming language. M The project provides version control for code changes and rollback capabilities. M The project is open source. M It is possible to contribute to the source. S The system is modular, allowing for easy modification of individual components. S Diagnostic tools are available to identify and troubleshoot issues. S"},{"location":"projects/amt/existing-tools/comparison/requirements/#security","title":"Security","text":"Requirement Priority The tool must protect data and system from unauthorized access, use, disclosure, disruption, modification, or destruction. M Regular security audits and penetration testing are conducted. S The tool enforce authorization controls based on user roles and permissions, restricting access to sensitive data and functionalities. C Data encryption is used for sensitive information at rest and in transit. C The project allows for regular security audits and penetration testing to identify vulnerabilities and ensure system integrity. C The tool implements backup functionality to ensure data availability in case of incidents. C"},{"location":"projects/amt/existing-tools/comparison/requirements/#compatibility","title":"Compatibility","text":"Requirement Priority The tool is compatible with existing systems and infrastructure. M The tool supports industry-standard data formats and protocols. M The tool operates seamlessly on supported operating systems and hardware platforms. S The tool supports commonly used data formats (e.g., CSV, Excel, JSON) for easy data exchange with other systems and tools. S The tool integrates with existing security solutions. C"},{"location":"projects/amt/existing-tools/comparison/requirements/#accessibility","title":"Accessibility","text":"Requirement Priority The tool is accessible to users with disabilities, following relevant accessibility standards (e.g., WCAG). S"},{"location":"projects/amt/existing-tools/comparison/requirements/#portability","title":"Portability","text":"Requirement Priority The tool support a range of operating systems (e.g., Windows, macOS, Linux) commonly used within an organization. S The tool minimizes dependencies on specific hardware or software configurations, promoting flexibility. S The tool offers a cloud-based deployment option or be compatible with cloud environments for scalability and accessibility. S The tool adheres to relevant cloud security standards and best practices. S"},{"location":"projects/amt/existing-tools/comparison/requirements/#deployment","title":"Deployment","text":"Requirement Priority The tool has an easy and user-friendly installation and configuration process. S The tool has on-premise or cloud-based deployment options to cater to different organizational needs and infrastructure. S"},{"location":"projects/amt/existing-tools/comparison/requirements/#legal-compliance","title":"Legal &amp; Compliance","text":"Requirement Priority It is clear how the tool is funded to avoid improper influence due to conflicts of interest M The tool is compliant with relevant legal and regulatory requirements. S The tool adheres to (local) data privacy regulations like GDPR, ensuring the protection of user data. S The tool implements appropriate security measures to comply with industry regulations and standards. S The tool is licensed for use within the organization according to the terms and conditions of the license agreement. S The tool respects intellectual property rights and avoid copyright infringement issues. S"},{"location":"projects/amt/existing-tools/comparison/tools/","title":"Research of tools for Transparency of Algorithmic Decision making","text":""},{"location":"projects/amt/existing-tools/comparison/tools/#research-of-tools-for-transparency-of-algorithmic-decision-making","title":"Research of tools for Transparency of Algorithmic Decision making","text":"<p>In our ongoing research on AI validation and transparency, we are seeking tools to support assessments. Ideal tools would combine various technical tests with checklists and questionnaires and have the ability to generate reports in both human-friendly and machine-exchangeable formats.</p> <p>This document contains a list of tools we have found and may want to investigate further.</p>"},{"location":"projects/amt/existing-tools/comparison/tools/#ai-verify","title":"AI Verify","text":"<p>AI Verify is an AI governance testing framework and software toolkit that validates the performance of AI systems against a set of  internationally recognized principles through standardized tests, and is consistent with international AI governance frameworks such as those from European Union, OECD and Singapore.</p> <p>Links: AI Verify Homepage, AI Verify documentation, AI Verify Github.</p>"},{"location":"projects/amt/existing-tools/comparison/tools/#to-investigate-further","title":"To investigate further","text":""},{"location":"projects/amt/existing-tools/comparison/tools/#verifyml","title":"VerifyML","text":"<p>What is it? VerifyML is an opinionated, open-source toolkit and workflow to help companies implement human-centric AI practices. It seems pretty much equivalent to AI Verify.</p> <p>Why interesting? The functionality of this toolkit seems to match closely with those of AI Verify. It has a \"git and code first approach\" and has automatic generation of model cards.</p> <p>Remarks The code seems to be last updated 2 years ago.</p> <p>Links: VerifyML, VerifyML GitHub</p>"},{"location":"projects/amt/existing-tools/comparison/tools/#ibm-research-360-toolkit","title":"IBM Research 360 Toolkit","text":"<p>What is it? Open source Python libraries that supports interpretability and explainability of datasets and machine learning models. Most relevant toolkits are the AI Fairness 360 and AI Explainability 360.</p> <p>Why interesting? Seems to encompass extensive fairness and explainability tests. Codebase seems to be active.</p> <p>Remarks It comes as Python and R libraries.</p> <p>Links: AI Fairness 360 Github, AI Explainability 360 Github.</p>"},{"location":"projects/amt/existing-tools/comparison/tools/#holistic-ai","title":"Holistic AI","text":"<p>What is it? Open source tool to assess and improve the trustworthiness of AI systems. Offers tools to measure and mitigate bias across numerous tasks. Will be extended to include tools for efficacy, robustness, privacy and explainability.</p> <p>Why interesting? Although it is not entirely clear what exactly this tool does (see Remarks) it does seem (according to their website) to provide reports on bias and fairness. The Github rep does not seem to include any report generating code, but mainly technical tests. This tutorial is an example in which bias is measured in a classification model.</p> <p>Remarks Website seems to suggest the possibility to generate reports, but this is not directly reflected in the codebase. Possibly reports are only available with some sort of licensed product?</p> <p>Links: Holistic AI Homepage, Holistic AI Github.</p>"},{"location":"projects/amt/existing-tools/comparison/tools/#ai-assessment-tool","title":"AI Assessment Tool","text":"<p>What is it? The tool is based on the ALTAI published by the European Commission. It is more of a discussion tool about AI Systems.</p> <p>Why interesting? Although it only includes questionnaires it does give an interesting way of reporting the end results. Discussions on for example IAMA can be documented as well within the tool.</p> <p>Remarks The tool of the EU itself is not open-source but the tool from Belgium is. Does not include any technical tests at this point.</p> <p>Links: AI Assessment Tool Belgium homepage AI Assessment Tool Belgium Github</p>"},{"location":"projects/amt/existing-tools/comparison/tools/#interesting-to-mention","title":"Interesting to mention","text":"<ul> <li> <p>What-if. Provides interface for expanding understanding of a black-box classification or regression ML model. Can be accessed through TensorBoard or as an extension in a Jupyter or Colab notebook. Does not seem to be an active codebase.</p> </li> <li> <p>Aequitas. Open source bias auditing and Fair ML toolkit. This already seems to be contained within AI Verify, at least the 'fairness tree'.</p> </li> <li> <p>Facets. Open source toolkit for understanding and analyzing ML datasets. Note that does not include ML models.</p> </li> <li> <p>Fairness Indicators. Open source Python package which enables easy computation of commonly-identified fairness metrics for binary and multiclass classifiers. Part of TensorFlow. k</p> </li> <li> <p>Fairlearn. Open source Python package that empowers developers of AI systems to assess their system's fairness and mitigate any observed unfairness issues.</p> </li> <li> <p>Dalex. The DALEX package x-rays any model and helps to explore and explain its behavior, helps to understand how complex models are working. The main function explain() creates a wrapper around a predictive model. Wrapped models may then be explored and compared with a collection of local and global explainers. Recent developments from the area of Interpretable Machine Learning/eXplainable Artificial Intelligence.</p> </li> <li> <p>SigmaRed. SigmaRed platform enables comprehensive third-party AI risk management (AI TPRM) and rapidly reduces the cycle time of conducting AI risks assessments while providing deep visibility, control, stakeholder based reporting, and detailed evidence repository. Does not seem to be open source.</p> </li> <li> <p>Anch.ai. The end-to-end cloud solution empowers global data-driven organizations to govern and deploy responsible, transparent, and explainable AI aligned with upcoming EU regulation AI Act. Does not seem to be open source.</p> </li> <li> <p>CredoAI. Credo AI is an AI governance platform that helps companies adopt, scale, and govern AI safely and effectively. Does not seem to be open source.</p> </li> </ul>"},{"location":"projects/amt/existing-tools/comparison/tools/#the-fate-system","title":"The FATE system","text":"<p>Paper by TNO about the FATE system. Acronym stands for \"FAir, Transparent and Explainable Decision Making.\"</p> <p>Tools mentioned include some of the above: Aequitas, AI Fairness 360, Dalex, Fairlearn, Responsibly, and What-If-Tool</p> <p>Links: Paper, Article, Microsoft links.</p>"},{"location":"projects/amt/existing-tools/comparison/tools_comparison/","title":"Comparison of tools for transparency of algorithmic decision making","text":""},{"location":"projects/amt/existing-tools/comparison/tools_comparison/#comparison-of-tools-for-transparency-of-algorithmic-decision-making","title":"Comparison of tools for transparency of algorithmic decision making","text":"<p>We have researched a few tools which we want to investigate further, this document is the next step in that investigation. We created a checklist to compare these tools against. The Fulfilled column will give a numerical value based on whether that requirement is fulfilled or not between 0 and 1. Then the actual scoring is the fulfilled value times the priority (the priority is translated to numerical values in the following way: {M:4, S:3, C:2, W:-1}).</p>"},{"location":"projects/amt/existing-tools/comparison/tools_comparison/#summary-of-the-comparison","title":"Summary of the comparison","text":"Requirement AIVerify VerifyML IBM 360 Research Toolkit Holistic AI AI Assessment Tool Functionality 36 42 20 17 22.85 Reliability 13 4 16 16 15.4 Usability 9.4 0 0 0 13 Help &amp; Documentation 2.8 1.5 6.4 1.6 0.55 Performance Efficiency 7.5 11 11 11 11 Maintainability 15.8 24.5 29 23.5 25.6 Security 8.3 2 2 2 7.5 Compatibility 12.5 14 14 10 11 Accessibility 0 0 0 0 0.3 Portability 10.5 4.5 5.1 7.5 11.4 Deployment 1.5 0.6 1.2 3.6 3 Legal &amp; Compliance 19 16 16 16 19 Total 136.3 120.1 120.7 108.2 140.6"},{"location":"projects/amt/existing-tools/comparison/tools_comparison/#notable-differences-between-the-tools","title":"Notable differences between the tools","text":"<p>AIVerify notes:</p> <ul> <li> <p>Technical tests are supported, but it can be quite slow because of overhead of the tool</p> </li> <li> <p>More flexibility would need to be built in before people could use the technical tests</p> <ul> <li> <p>If you have many variables you are not able to show it in the pdf</p> </li> <li> <p>The error messages in why technical tests don't work on the model are not user-friendly</p> </li> </ul> </li> </ul> <p>VerifyML notes:</p> <ul> <li> <p>This tool is not actively developed anymore, parties transferred their focus to AIVerify</p> </li> <li> <p>This tool does not support for assessments</p> </li> </ul> <p>IBM 360 toolkit notes:</p> <ul> <li> <p>The toolkit has a strong backing of the industry and the community</p> </li> <li> <p>There are many technical tests included from the latest research, and also supports mitigation algorithms</p> </li> <li> <p>It is purely for developers and has therefore no support for assessments</p> </li> </ul> <p>Holistic AI:</p> <ul> <li> <p>Like IBM 360 Toolkit it does differentiate to different type of technical assessments like bias and explainability, but it is less extensive than the 360 toolkit</p> </li> <li> <p>The ambition is large of Holistic AI, they want to capture, Efficacy, Robustness, and Privacy tests as well</p> </li> <li> <p>It is a private company from the United Kingdom which has open sourced part of their tool</p> </li> </ul> <p>AI Assessment Tool:</p> <ul> <li> <p>This tool does not have any technical tests, but outshines the others with the discussion on assessment option</p> </li> <li> <p>It is also very performant</p> </li> </ul>"},{"location":"projects/amt/existing-tools/comparison/tools_comparison/#summary-per-tool-in-one-sentence","title":"Summary per tool in one sentence","text":"<ul> <li> <p><code>AIVerify</code> is a tool with a UI to execute both assessments and technical tests.</p> </li> <li> <p><code>VerifyML</code> is a Python package to generate Model Cards.</p> </li> <li> <p><code>Holistic AI</code> is a Python package to test for and mitigate Bias in your model.</p> </li> <li> <p><code>IBM 360 Research Toolkit</code> is a Python and R package to test for Fairness &amp; Explainability of your model.</p> </li> <li> <p><code>AI Assessment Tool</code> is a tool with a UI to execute assessments and log discussions.</p> </li> </ul>"},{"location":"projects/llm-benchmarks/","title":"LLM Benchmarks","text":""},{"location":"projects/llm-benchmarks/#llm-benchmarks","title":"LLM Benchmarks","text":""},{"location":"projects/llm-benchmarks/#context","title":"Context","text":"<p>Large Languages Models (LLMs) are becoming increasingly popular in assisting people in a variety of tasks. These tasks include, but are not limited to, information retrieval, assisting with coding and essay writing. In the context of the government, tasks can include for example supporting Freedom of Information Act (FOIA) requests and aiding in answering questions of citizens.</p> <p>While the potential benefit of using LLMs is large, there are also significant risks. Basically an LLM is just a next token predictor, which bases its predictions on the user input (context) and on compressed information seen during training (LLM parameters); hence there is no guarantee on the quality and correctness of the output. Moreover, due to bias in the training data, LLMs can have bias in their output, despite best efforts to mitigate this. Additionally, we have human values that we expect LLMs to be aligned with. Certainly, within the context of a government, we should take utmost care not to discriminate. To assess the quality, correctness, bias and alignment with human values of an LLM one can perform benchmarks.</p>"},{"location":"projects/llm-benchmarks/#the-project","title":"The project","text":"<p>The LLM Benchmarks project of the AI Validation Team aims to create a platform where LLMs can be measured across a wide range of benchmarks. We limit ourselves to LLMs and benchmarks that are related to the Dutch society. Both LLMs and the benchmarks can be configured by users of the platform. Users can run these benchmarks on LLMs on our platform. The intended goal of this project is to give government organizations, citizens and companies insight in the various LLMs and their quality, correctness, bias and alignment with human values. The project also encompasses a dashboard with uploaded LLMs and their performance on uploaded benchmarks. With this platform we aim to enhance public trust in the usage of LLMs and expose potential bias that exists within LLMs.</p>"}]}