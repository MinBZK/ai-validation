# Research of tools for transparency of algorithmic decision making

In our ongoing research on AI validation and transparency, we are seeking tools to support assessments.
Ideal tools would combine various technical tests with checklists and questionnaires and have the ability to generate
reports in both human-friendly and machine-exchangeable formats.

This document contains a list of tools we have found and may want to investigate further.

## AI Verify

AI Verify is an AI governance testing framework and software toolkit that validates the performance of AI systems against
a set of  internationally recognised principles through standardised tests, and is consistent with international AI governance
frameworks such as those from European Union, OECD and Singapore.

Links:
[AI Verify Homepage](https://aiverifyfoundation.sg/)
[AIVerify documentation](https://imda-btg.github.io/aiverify/)
[AIVerify Github](https://github.com/IMDA-BTG/aiverify)

## AI Assessment Tool Belgium

The tool is based on the ALTAI recommendations published by the European Commission and is designed to help
organizations ensure their AI systems are transparent, robust, and trustworthy.

Links:
[Altai Homepage](https://altai.ai4belgium.be/)
[Altai Github](https://github.com/AI4Belgium/ai-assessment-tool)
